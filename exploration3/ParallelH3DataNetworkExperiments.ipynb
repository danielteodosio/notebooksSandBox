{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def carregar_pickle(nome_arquivo):\n",
    "  with open(nome_arquivo, 'rb') as arquivo:\n",
    "    objeto = pickle.load(arquivo)\n",
    "  return objeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando h3 w3_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set1 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_full1 = raw_data_set1['inputs']\n",
    "output_full1 = raw_data_set1['outputs']\n",
    "sequences_full1 = raw_data_set1['sequences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando h3 w12_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set2 = carregar_pickle('dataset_H3_W12S4.pkl')\n",
    "input_full2 = raw_data_set2['inputs']\n",
    "output_full2 = raw_data_set2['outputs']\n",
    "sequences_full2 = raw_data_set2['sequences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando multiplas representações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_setR0 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_fullR0 = raw_data_setR0['inputs']\n",
    "output_fullR0 = raw_data_setR0['outputs']\n",
    "sequences_fullR0 = raw_data_setR0['sequences']\n",
    "\n",
    "raw_data_setR1 = carregar_pickle('dataset_H3_W12S4.pkl')\n",
    "input_fullR1 = raw_data_setR1['inputs']\n",
    "output_fullR1 = raw_data_setR1['outputs']\n",
    "sequences_fullR1 = raw_data_setR1['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of difs: 0\n",
      "Ordem OK\n"
     ]
    }
   ],
   "source": [
    "validaSequencesOrder(sequences_fullR0, sequences_fullR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14963, 497, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fullR0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando datasets w3_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train1, input_test1, output_train1, output_test1, sequence_train1, sequence_test1 = train_test_split(input_full1, output_full1, \n",
    "sequences_full1, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando datasets w12_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train2, input_test2, output_train2, output_test2, sequence_train2, sequence_test2 = train_test_split(input_full2, output_full2, \n",
    "sequences_full2, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando dataset conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_trainR0, input_testR0, input_trainR1, input_testR1, output_trainConj, output_testConj, sequence_trainConj, sequence_testConj = train_test_split(input_fullR0, input_fullR1, output_fullR0, \n",
    "sequences_fullR0, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11222, 122, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_trainR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# binariza resultado da classificação da RN. \n",
    "#param: array -> Rn output, corte -> x > corte significa 1\n",
    "def myClassify(array, corte):\n",
    "    classifiedArray = []\n",
    "    for x in array:\n",
    "        if(x > corte):\n",
    "            classifiedArray.append(1)\n",
    "        else:\n",
    "            classifiedArray.append(0)\n",
    "    \n",
    "    return classifiedArray\n",
    "\n",
    "# Retorna lista com Ok/Nok para predição binarizada  e valor real\n",
    "# param: arrPredict -> predict da rede\n",
    "# param: arrReal -> valores reais de referência\n",
    "def comparePredictOkNok(arrPredict, arrReal):\n",
    "\n",
    "    sizePredict = len(arrPredict)\n",
    "    sizeArrReal = len(arrReal)\n",
    "\n",
    "    if(sizePredict != sizeArrReal):\n",
    "        print('tamanho dos arrays é imcompatível')\n",
    "        return\n",
    "\n",
    "    size = sizeArrReal\n",
    "\n",
    "    arrOkNok = []\n",
    "    for i in range(0, size):\n",
    "        if(arrPredict[i] == arrReal[i]):\n",
    "            arrOkNok.append('OK')\n",
    "        else:\n",
    "            arrOkNok.append('NOK')\n",
    "    \n",
    "    return arrOkNok\n",
    "\n",
    "\n",
    "\n",
    "# Retorna lista com Ok/Nok para predição binarizada  e valor real\n",
    "# param: arrPredict -> predict da rede\n",
    "# param: arrReal -> valores reais de referência\n",
    "# param: sequenceTest -> sequencia correspondente\n",
    "def comparePredictOkNokWithSeq(arrPredict, arrReal, sequenceTest):\n",
    "\n",
    "    sizePredict = len(arrPredict)\n",
    "    sizeArrReal = len(arrReal)\n",
    "\n",
    "    if(sizePredict != sizeArrReal):\n",
    "        print('tamanho dos arrays é imcompatível')\n",
    "        return\n",
    "\n",
    "    size = sizeArrReal\n",
    "\n",
    "    arrOkNok = []\n",
    "    for i in range(0, size):\n",
    "        if(arrPredict[i] == arrReal[i]):\n",
    "            arrOkNok.append('OK' + ' : ' + sequenceTest[i])\n",
    "        else:\n",
    "            arrOkNok.append('NOK' + ' : ' + sequenceTest[i])\n",
    "    \n",
    "    return arrOkNok\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyIfSeqWindowAndStrideMatches(seqSize, windowSize, strideSize):\n",
    "    last_window_start = 0\n",
    "    nOfStrides = 0\n",
    "    while (last_window_start + windowSize - 1) < (seqSize - 1):\n",
    "        last_window_start = strideSize * nOfStrides\n",
    "        nOfStrides = nOfStrides + 1\n",
    "        #print(last_window_start)\n",
    "        #print(nOfStrides)\n",
    "        #print(' ')\n",
    "\n",
    "    print('n of windows: ' + str(nOfStrides))\n",
    "    print('last window start: ' + str(last_window_start))\n",
    "    print('last window end: ' + str(last_window_start + windowSize - 1))\n",
    "    print('max seq position: ' + str(seqSize - 1))\n",
    "\n",
    "\n",
    "\n",
    "def validaSequencesOrder(seq0, seq1):\n",
    "    i = 0\n",
    "    d = 0\n",
    "    while i < len(seq0):\n",
    "        #print(seq0[i][0:15] + ' - ' + seq1[i][0:15])\n",
    "        if(seq0[i] != seq1[i]):\n",
    "            d = d+1\n",
    "        i = i + 1\n",
    "\n",
    "    if d > 0:\n",
    "        print('n of difs: ' + str(d))\n",
    "        print('Ordem NOK')\n",
    "    else:\n",
    "        print('n of difs: ' + str(d))\n",
    "        print('Ordem OK')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of windows: 7\n",
      "last window start: 30\n",
      "last window end: 37\n",
      "max seq position: 37\n"
     ]
    }
   ],
   "source": [
    "verifyIfSeqWindowAndStrideMatches(38,8,5)   # 38,8,5 -> 7    #163, 37, 21 => 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train1[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implementação funcional paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputR0 = keras.Input(shape=(497, 16)) \n",
    "conv1R0 = keras.layers.Conv1D(7, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (497, 16), use_bias= True)(inputR0)\n",
    "pool1R0 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R0)\n",
    "conv2R0 = keras.layers.Conv1D(16, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R0)\n",
    "pool2R0 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R0)\n",
    "#flatR0 = keras.layers.Flatten()(pool2R0)\n",
    "\n",
    "inputR1 = keras.Input(shape=(122, 52)) \n",
    "conv1R1 = keras.layers.Conv1D(7, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (122, 52), use_bias= True)(inputR1)\n",
    "pool1R1 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R1)\n",
    "conv2R1 = keras.layers.Conv1D(16, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (38, 10), use_bias= True)(pool1R1)\n",
    "pool2R1 = keras.layers.AveragePooling1D(pool_size=8, strides= 5, padding='valid')(conv2R1)\n",
    "#flatR1 =  keras.layers.Flatten()(pool2R1)\n",
    "\n",
    "concatenate_filters = keras.layers.concatenate([pool2R0, pool2R1])\n",
    "\n",
    "convOut = keras.layers.Conv1D(200, kernel_size= 1, strides= 1, \n",
    "                              padding='valid', activation='relu', use_bias= True)(concatenate_filters)\n",
    "\n",
    "poolOut = keras.layers.GlobalAveragePooling1D()(convOut)\n",
    "\n",
    "flatOut =  keras.layers.Flatten()(poolOut)\n",
    "\n",
    "dense1 = keras.layers.Dense(200, activation=keras.layers.LeakyReLU(alpha=0.3))(flatOut)  #keras.layers.LeakyReLU(alpha=0.3)\n",
    "dense2 = keras.layers.Dense(32, activation=keras.layers.LeakyReLU(alpha=0.3))(dense1)\n",
    "#dense3 = keras.layers.Dense(10, activation=keras.layers.LeakyReLU(alpha=0.3))(dense2)\n",
    "outpu1 = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "model = keras.Model(inputs= [inputR0, inputR1], outputs=outpu1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CNN = keras.Sequential()\n",
    "\n",
    "# CNN.add(keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (122, 52), use_bias= True))    #activation='relu'\n",
    "# CNN.add(keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid'))\n",
    "\n",
    "# CNN.add(keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', \n",
    "#                             activation='relu', input_shape = (38, 10), use_bias= True))\n",
    "# #CNN.add(keras.layers.AveragePooling1D(pool_size=8, strides= 5, padding='valid'))\n",
    "# CNN.add(keras.layers.GlobalAveragePooling1D())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 497, 16)]    0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 122, 52)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 497, 7)       119         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 122, 7)       371         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 163, 7)      0           ['conv1d[0][0]']                 \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling1d_2 (AveragePo  (None, 38, 7)       0           ['conv1d_2[0][0]']               \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 163, 16)      128         ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 38, 16)       128         ['average_pooling1d_2[0][0]']    \n",
      "                                                                                                  \n",
      " average_pooling1d_1 (AveragePo  (None, 7, 16)       0           ['conv1d_1[0][0]']               \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling1d_3 (AveragePo  (None, 7, 16)       0           ['conv1d_3[0][0]']               \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7, 32)        0           ['average_pooling1d_1[0][0]',    \n",
      "                                                                  'average_pooling1d_3[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 7, 200)       6600        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 200)         0           ['conv1d_4[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 200)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 200)          40200       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           6432        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,011\n",
      "Trainable params: 54,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();\n",
    "#keras.utils.plot_model(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implemetação paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(reduction='sum_over_batch_size'), metrics=['accuracy']\n",
    "            , optimizer= keras.optimizers.Adam(learning_rate=0.001))   #sum_over_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 40s 172ms/step - loss: 0.6373 - accuracy: 0.6201 - val_loss: 0.5147 - val_accuracy: 0.7516\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 36s 171ms/step - loss: 0.5147 - accuracy: 0.7505 - val_loss: 0.4899 - val_accuracy: 0.7703\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 40s 192ms/step - loss: 0.4967 - accuracy: 0.7638 - val_loss: 0.4739 - val_accuracy: 0.7815\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 86s 410ms/step - loss: 0.4796 - accuracy: 0.7757 - val_loss: 0.4783 - val_accuracy: 0.7734\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 67s 315ms/step - loss: 0.4697 - accuracy: 0.7840 - val_loss: 0.4606 - val_accuracy: 0.7913\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 45s 212ms/step - loss: 0.4657 - accuracy: 0.7829 - val_loss: 0.5029 - val_accuracy: 0.7561\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 44s 209ms/step - loss: 0.4484 - accuracy: 0.7973 - val_loss: 0.4402 - val_accuracy: 0.8022\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 49s 234ms/step - loss: 0.4394 - accuracy: 0.8013 - val_loss: 0.4254 - val_accuracy: 0.8084\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 29s 140ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4234 - val_accuracy: 0.8140\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 30s 140ms/step - loss: 0.4100 - accuracy: 0.8188 - val_loss: 0.4210 - val_accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.4086 - accuracy: 0.8195 - val_loss: 0.4147 - val_accuracy: 0.8184\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 32s 152ms/step - loss: 0.4056 - accuracy: 0.8213 - val_loss: 0.3988 - val_accuracy: 0.8269\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.4116 - accuracy: 0.8191 - val_loss: 0.4083 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3895 - accuracy: 0.8304 - val_loss: 0.3962 - val_accuracy: 0.8274\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3927 - accuracy: 0.8296 - val_loss: 0.4241 - val_accuracy: 0.8115\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.3838 - accuracy: 0.8323 - val_loss: 0.3909 - val_accuracy: 0.8327\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 37s 177ms/step - loss: 0.3917 - accuracy: 0.8273 - val_loss: 0.3993 - val_accuracy: 0.8262\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.3859 - accuracy: 0.8331 - val_loss: 0.3933 - val_accuracy: 0.8334\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.3805 - accuracy: 0.8325 - val_loss: 0.3906 - val_accuracy: 0.8354\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.3793 - accuracy: 0.8353 - val_loss: 0.4054 - val_accuracy: 0.8238\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3847 - accuracy: 0.8326 - val_loss: 0.3978 - val_accuracy: 0.8323\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.3766 - accuracy: 0.8375 - val_loss: 0.4031 - val_accuracy: 0.8289\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 31s 147ms/step - loss: 0.3737 - accuracy: 0.8421 - val_loss: 0.4088 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.3751 - accuracy: 0.8402 - val_loss: 0.3829 - val_accuracy: 0.8374\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3712 - accuracy: 0.8429 - val_loss: 0.3892 - val_accuracy: 0.8343\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.3710 - accuracy: 0.8455 - val_loss: 0.4281 - val_accuracy: 0.8160\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3696 - accuracy: 0.8449 - val_loss: 0.3967 - val_accuracy: 0.8271\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 24s 113ms/step - loss: 0.3650 - accuracy: 0.8424 - val_loss: 0.3852 - val_accuracy: 0.8392\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.3679 - accuracy: 0.8470 - val_loss: 0.3792 - val_accuracy: 0.8423\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.3723 - accuracy: 0.8399 - val_loss: 0.4180 - val_accuracy: 0.8187\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.3625 - accuracy: 0.8501 - val_loss: 0.3835 - val_accuracy: 0.8374\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.3569 - accuracy: 0.8487 - val_loss: 0.3808 - val_accuracy: 0.8405\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.3624 - accuracy: 0.8494 - val_loss: 0.3830 - val_accuracy: 0.8405\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 24s 113ms/step - loss: 0.3641 - accuracy: 0.8485 - val_loss: 0.3809 - val_accuracy: 0.8349\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 54s 255ms/step - loss: 0.3566 - accuracy: 0.8494 - val_loss: 0.3921 - val_accuracy: 0.8242\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 37s 175ms/step - loss: 0.3552 - accuracy: 0.8518 - val_loss: 0.4365 - val_accuracy: 0.8089\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 48s 226ms/step - loss: 0.3588 - accuracy: 0.8513 - val_loss: 0.3774 - val_accuracy: 0.8432\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 50s 235ms/step - loss: 0.3542 - accuracy: 0.8519 - val_loss: 0.3862 - val_accuracy: 0.8331\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 44s 210ms/step - loss: 0.3483 - accuracy: 0.8543 - val_loss: 0.3917 - val_accuracy: 0.8340\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 44s 211ms/step - loss: 0.3443 - accuracy: 0.8542 - val_loss: 0.3708 - val_accuracy: 0.8383\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 32s 151ms/step - loss: 0.3548 - accuracy: 0.8516 - val_loss: 0.4348 - val_accuracy: 0.8071\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3491 - accuracy: 0.8567 - val_loss: 0.3812 - val_accuracy: 0.8458\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 39s 186ms/step - loss: 0.3510 - accuracy: 0.8492 - val_loss: 0.3731 - val_accuracy: 0.8425\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 34s 160ms/step - loss: 0.3436 - accuracy: 0.8585 - val_loss: 0.3678 - val_accuracy: 0.8429\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 31s 147ms/step - loss: 0.3466 - accuracy: 0.8558 - val_loss: 0.3725 - val_accuracy: 0.8387\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.3459 - accuracy: 0.8531 - val_loss: 0.3793 - val_accuracy: 0.8389\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.3461 - accuracy: 0.8539 - val_loss: 0.3680 - val_accuracy: 0.8407\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.3354 - accuracy: 0.8604 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.3346 - accuracy: 0.8573 - val_loss: 0.4136 - val_accuracy: 0.8218\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 30s 142ms/step - loss: 0.3385 - accuracy: 0.8556 - val_loss: 0.3812 - val_accuracy: 0.8432\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.3476 - accuracy: 0.8510 - val_loss: 0.3641 - val_accuracy: 0.8474\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 24s 113ms/step - loss: 0.3279 - accuracy: 0.8622 - val_loss: 0.3644 - val_accuracy: 0.8465\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.3277 - accuracy: 0.8640 - val_loss: 0.3654 - val_accuracy: 0.8425\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.3247 - accuracy: 0.8681 - val_loss: 0.3766 - val_accuracy: 0.8427\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 31s 149ms/step - loss: 0.3289 - accuracy: 0.8629 - val_loss: 0.3668 - val_accuracy: 0.8490\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.3244 - accuracy: 0.8653 - val_loss: 0.4114 - val_accuracy: 0.8278\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.3264 - accuracy: 0.8623 - val_loss: 0.3645 - val_accuracy: 0.8429\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 35s 167ms/step - loss: 0.3187 - accuracy: 0.8694 - val_loss: 0.3641 - val_accuracy: 0.8487\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 42s 198ms/step - loss: 0.3248 - accuracy: 0.8640 - val_loss: 0.3694 - val_accuracy: 0.8365\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 31s 149ms/step - loss: 0.3205 - accuracy: 0.8669 - val_loss: 0.3600 - val_accuracy: 0.8445\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.3231 - accuracy: 0.8641 - val_loss: 0.3749 - val_accuracy: 0.8349\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3204 - accuracy: 0.8674 - val_loss: 0.3702 - val_accuracy: 0.8374\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 23s 110ms/step - loss: 0.3172 - accuracy: 0.8657 - val_loss: 0.3634 - val_accuracy: 0.8427\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.3158 - accuracy: 0.8680 - val_loss: 0.3686 - val_accuracy: 0.8456\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 24s 113ms/step - loss: 0.3120 - accuracy: 0.8694 - val_loss: 0.3773 - val_accuracy: 0.8398\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.3146 - accuracy: 0.8711 - val_loss: 0.3640 - val_accuracy: 0.8432\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3146 - accuracy: 0.8700 - val_loss: 0.3723 - val_accuracy: 0.8421\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 43s 204ms/step - loss: 0.3127 - accuracy: 0.8709 - val_loss: 0.3899 - val_accuracy: 0.8343\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 34s 159ms/step - loss: 0.3135 - accuracy: 0.8697 - val_loss: 0.3865 - val_accuracy: 0.8265\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3097 - accuracy: 0.8729 - val_loss: 0.3636 - val_accuracy: 0.8465\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.3103 - accuracy: 0.8683 - val_loss: 0.3705 - val_accuracy: 0.8427\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.3002 - accuracy: 0.8770 - val_loss: 0.3791 - val_accuracy: 0.8423\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 24s 112ms/step - loss: 0.3045 - accuracy: 0.8742 - val_loss: 0.3892 - val_accuracy: 0.8372\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3068 - accuracy: 0.8690 - val_loss: 0.3841 - val_accuracy: 0.8401\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3064 - accuracy: 0.8693 - val_loss: 0.3691 - val_accuracy: 0.8443\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3085 - accuracy: 0.8709 - val_loss: 0.3812 - val_accuracy: 0.8360\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.3030 - accuracy: 0.8745 - val_loss: 0.3590 - val_accuracy: 0.8441\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.2972 - accuracy: 0.8798 - val_loss: 0.3746 - val_accuracy: 0.8407\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2976 - accuracy: 0.8748 - val_loss: 0.3664 - val_accuracy: 0.8427\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 38s 180ms/step - loss: 0.2918 - accuracy: 0.8781 - val_loss: 0.3664 - val_accuracy: 0.8432\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.2886 - accuracy: 0.8782 - val_loss: 0.3840 - val_accuracy: 0.8369\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.2896 - accuracy: 0.8816 - val_loss: 0.3673 - val_accuracy: 0.8499\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.2891 - accuracy: 0.8813 - val_loss: 0.3659 - val_accuracy: 0.8479\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.2944 - accuracy: 0.8782 - val_loss: 0.3595 - val_accuracy: 0.8465\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.2899 - accuracy: 0.8803 - val_loss: 0.3868 - val_accuracy: 0.8358\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.2944 - accuracy: 0.8801 - val_loss: 0.3553 - val_accuracy: 0.8481\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 32s 151ms/step - loss: 0.2920 - accuracy: 0.8816 - val_loss: 0.3625 - val_accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.2804 - accuracy: 0.8882 - val_loss: 0.3711 - val_accuracy: 0.8432\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.2774 - accuracy: 0.8861 - val_loss: 0.3839 - val_accuracy: 0.8396\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.2819 - accuracy: 0.8886 - val_loss: 0.3710 - val_accuracy: 0.8474\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2881 - accuracy: 0.8862 - val_loss: 0.3677 - val_accuracy: 0.8479\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 28s 130ms/step - loss: 0.2806 - accuracy: 0.8831 - val_loss: 0.3696 - val_accuracy: 0.8463\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 31s 148ms/step - loss: 0.2713 - accuracy: 0.8905 - val_loss: 0.3678 - val_accuracy: 0.8463\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.2808 - accuracy: 0.8816 - val_loss: 0.3751 - val_accuracy: 0.8392\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2731 - accuracy: 0.8873 - val_loss: 0.4299 - val_accuracy: 0.8209\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2801 - accuracy: 0.8844 - val_loss: 0.4207 - val_accuracy: 0.8376\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.2746 - accuracy: 0.8849 - val_loss: 0.3966 - val_accuracy: 0.8378\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2652 - accuracy: 0.8914 - val_loss: 0.3760 - val_accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 24s 112ms/step - loss: 0.2681 - accuracy: 0.8908 - val_loss: 0.3743 - val_accuracy: 0.8485\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2693 - accuracy: 0.8891 - val_loss: 0.3877 - val_accuracy: 0.8456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "historyf = model.fit([input_trainR0, input_trainR1], output_trainConj, epochs= 100, batch_size = 32, \n",
    "                     validation_split = 0.4, shuffle= True, callbacks=[callback]) # validation_split = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBest = keras.models.load_model('best_model_10050525.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 7ms/step - loss: 0.3812 - accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3812302052974701, 0.8460304737091064]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate([input_testR0, input_testR1], output_testConj, batch_size= 32)\n",
    "#modelBest.evaluate([input_testR0, input_testR1], output_testConj, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistoryf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(historyf\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(historyf.history['accuracy'])\n",
    "plt.plot(historyf.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498551845550537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(historyf.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7476052641868591,\n",
       " 0.7576297521591187,\n",
       " 0.7885943651199341,\n",
       " 0.7794609069824219,\n",
       " 0.7190911173820496,\n",
       " 0.7894853949546814,\n",
       " 0.7972822189331055,\n",
       " 0.7687680721282959,\n",
       " 0.8019603490829468,\n",
       " 0.7714412808418274,\n",
       " 0.8108710050582886,\n",
       " 0.8124303817749023,\n",
       " 0.8182223439216614,\n",
       " 0.8115392923355103,\n",
       " 0.8191133737564087,\n",
       " 0.8200044631958008,\n",
       " 0.8099799752235413,\n",
       " 0.8251280784606934,\n",
       " 0.8157718777656555,\n",
       " 0.7848073244094849,\n",
       " 0.8010692596435547,\n",
       " 0.8298062086105347,\n",
       " 0.8278012871742249,\n",
       " 0.8226776719093323,\n",
       " 0.8351525664329529,\n",
       " 0.8135442137718201,\n",
       " 0.8298062086105347,\n",
       " 0.8269101977348328,\n",
       " 0.8246825337409973,\n",
       " 0.8322566151618958,\n",
       " 0.8295834064483643,\n",
       " 0.8231232166290283,\n",
       " 0.8298062086105347,\n",
       " 0.8302517533302307,\n",
       " 0.8367119431495667,\n",
       " 0.8197816610336304,\n",
       " 0.8175539970397949,\n",
       " 0.8231232166290283,\n",
       " 0.8315883278846741,\n",
       " 0.8102027177810669,\n",
       " 0.824237048625946,\n",
       " 0.8313655853271484,\n",
       " 0.8322566151618958,\n",
       " 0.8304744958877563,\n",
       " 0.8135442137718201,\n",
       " 0.8398306965827942,\n",
       " 0.8088661432266235,\n",
       " 0.8327021598815918,\n",
       " 0.8282468318939209,\n",
       " 0.8324794173240662,\n",
       " 0.8211182951927185,\n",
       " 0.8213410377502441,\n",
       " 0.8329249024391174,\n",
       " 0.8322566151618958,\n",
       " 0.830697238445282,\n",
       " 0.8171085119247437,\n",
       " 0.8122076392173767,\n",
       " 0.8177767992019653,\n",
       " 0.8195589184761047,\n",
       " 0.8286923766136169,\n",
       " 0.8367119431495667,\n",
       " 0.8295834064483643,\n",
       " 0.8269101977348328,\n",
       " 0.8213410377502441,\n",
       " 0.8329249024391174,\n",
       " 0.8322566151618958,\n",
       " 0.8200044631958008,\n",
       " 0.8240142464637756,\n",
       " 0.8244597911834717,\n",
       " 0.8282468318939209,\n",
       " 0.8304744958877563,\n",
       " 0.8269101977348328,\n",
       " 0.818445086479187,\n",
       " 0.8251280784606934,\n",
       " 0.8093116283416748,\n",
       " 0.8251280784606934,\n",
       " 0.8159946799278259,\n",
       " 0.8340387344360352,\n",
       " 0.831142783164978,\n",
       " 0.8322566151618958,\n",
       " 0.836043655872345,\n",
       " 0.8327021598815918,\n",
       " 0.8324794173240662,\n",
       " 0.8275785446166992,\n",
       " 0.8211182951927185,\n",
       " 0.8347070813179016,\n",
       " 0.825796365737915,\n",
       " 0.8197816610336304,\n",
       " 0.8302517533302307,\n",
       " 0.8211182951927185,\n",
       " 0.8148808479309082,\n",
       " 0.8211182951927185,\n",
       " 0.8280240297317505,\n",
       " 0.8173312544822693,\n",
       " 0.8302517533302307,\n",
       " 0.8266874551773071,\n",
       " 0.8302517533302307,\n",
       " 0.8295834064483643,\n",
       " 0.8162174224853516,\n",
       " 0.8269101977348328]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historyf.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 3s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20535856],\n",
       "       [0.9682729 ],\n",
       "       [0.58951306],\n",
       "       ...,\n",
       "       [0.20562437],\n",
       "       [0.87147534],\n",
       "       [0.96062887]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictOnTest = model.predict([input_testR0, input_testR1])\n",
    "predictOnTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiedArrayPredict = myClassify(predictOnTest, 0.5)\n",
    "np.array(classifiedArrayPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OK : agagggtgtactccaagaagaggaagatgaggctagacgtctctgcatggagtatga',\n",
       " 'OK : gcaaaaataaatgcttgactctgtagcgggaaggcgtattatgcacaccccgcgccg',\n",
       " 'OK : ttcgtctccgcgactacgatgagatgcctgagtgcttccgttactggattgtcacca',\n",
       " 'OK : gtactagagaactagtgcattagcttatttttttgttatcatgctaaccacccggcg',\n",
       " 'OK : aaattaaaattttattgacttaggtcactaaatactttaaccaatataggcatagcg',\n",
       " 'OK : tatgaccgaacgagtcaatcagaccgctttgactctggtattactgtgaacattatt',\n",
       " 'OK : taacattaataaataaggaggctctaatggcactcattagccaatcaatcaagaact',\n",
       " 'OK : tttctacaaaacacttgatactgtatgagcatacagtataattgcttcaacagaaca',\n",
       " 'OK : atgcatttttccgcttgtcttcctgagccgactccctataatgcgcctccatcgaca',\n",
       " 'OK : tattggcttgctcaagcatgaactcaaggctgatacggcgagacttgcgagccttgt',\n",
       " 'OK : aacgagtcaatcagaccgctttgactctggtattactgtgaacattattcgtctccg',\n",
       " 'OK : tctgaaatgagctgttgacaattaatcatcgaactagttaactagtacgcaagttca',\n",
       " 'OK : cactaatttattccatgtcacacttttcgcatctttgttatgctatggttatttcat',\n",
       " 'OK : gaggtggctatgtgtatgaccgaacgagtcaatcagaccgctttgactctggtatta',\n",
       " 'OK : catgtcagcctcgacaacttgcataaatgctttcttgtagacgtgccctacgcgctt',\n",
       " 'NOK : tcagaaatattatggtgatgaactgtttttttatccagtataatttgttggcataat',\n",
       " 'OK : ctgcaatttttctattgcggcctgcggagaactccctataatgcgcctccatcgaca',\n",
       " 'OK : tgctgaaaggaggaactatatgcgctcatacgatatgaacgttgagactgccgctga',\n",
       " 'OK : tctcgtggatggacgttcaacattgaggaaggcataacgctactacctgatgtttac',\n",
       " 'OK : cgaacgagtcaatcagaccgctttgactctggtattactgtgaacattattcgtctc',\n",
       " 'OK : cctcaatggcctctaaacgggtcttgaggggttttttgctgaaaggaggaactatat',\n",
       " 'OK : cgacttaatatactgcgacaggacgtccgttctgtgtaaatcgcaatgaaatggttt',\n",
       " 'OK : catcctcgcaccagtcgacgacggtttacgctttacgtatagtggcgacaatttttt',\n",
       " 'OK : aaccattccggttgactcaatgagcatctcgatgcagcgtactcctacatgaataga',\n",
       " 'OK : taaaaaactaacagttgtcagcctgtcccgcttataagatcatacgccgttatacgt',\n",
       " 'OK : aattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaatactaacaaactc',\n",
       " 'OK : ttactgtgaacattattcgtctccgcgactacgatgagatgcctgagtgcttccgtt']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "comparePredictOkNokWithSeq(classifiedArrayPredict, output_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23533559,  0.42990232, -0.25082487, -0.15267515,  0.26705414,\n",
       "         0.41497964,  0.27988416,  0.37338895, -0.29958403, -0.04501176],\n",
       "       [ 0.42684212,  0.07528386,  0.28260273, -0.10901958, -0.15239488,\n",
       "         0.44041243,  0.01431945,  0.2730652 ,  0.4608476 ,  0.46495697],\n",
       "       [ 0.45438316,  0.02100177,  0.29724106, -0.24716143, -0.4676595 ,\n",
       "         0.4724816 , -0.3817394 ,  0.19320472,  0.42271256, -0.05679994],\n",
       "       [ 0.15253878, -0.10971248, -0.04070297, -0.21874414, -0.08176634,\n",
       "         0.28545243, -0.43704703,  0.18602677,  0.22525644,  0.47238237],\n",
       "       [-0.46574974, -0.4418646 , -0.38255867, -0.34078255, -0.23755996,\n",
       "         0.2713209 ,  0.27443305, -0.03233695,  0.24816659, -0.28621373],\n",
       "       [ 0.07085161,  0.39532802, -0.03007789, -0.32714292,  0.49284223,\n",
       "         0.18271512, -0.03359003, -0.21458982, -0.42486927,  0.06511235],\n",
       "       [ 0.2713358 , -0.27115414,  0.34532204, -0.23495436, -0.43641958,\n",
       "        -0.3368862 ,  0.12960823,  0.10995054, -0.19554421, -0.07720792],\n",
       "       [-0.04590143,  0.3942591 ,  0.00566856,  0.19669637, -0.06631317,\n",
       "        -0.42244568, -0.06407813, -0.1728232 ,  0.46452302,  0.21050097],\n",
       "       [ 0.08060884,  0.37193573, -0.354489  , -0.44815534, -0.00615418,\n",
       "        -0.2734092 ,  0.00961146,  0.40794468,  0.34805787,  0.3050058 ],\n",
       "       [-0.13335842, -0.24585015, -0.33572006, -0.45683667, -0.01444119,\n",
       "        -0.10833547, -0.05962682, -0.15336625, -0.36658153,  0.31347117],\n",
       "       [-0.19820169, -0.153704  , -0.04638202,  0.4839829 ,  0.26289713,\n",
       "        -0.2991848 ,  0.3665354 ,  0.22821838,  0.07212699, -0.3094584 ],\n",
       "       [-0.00911083,  0.29570737, -0.16099177, -0.26788437,  0.39560342,\n",
       "        -0.16354184, -0.44186142, -0.35942614,  0.35737228,  0.10719667],\n",
       "       [-0.15877792,  0.34966612,  0.01691701, -0.06887166,  0.12856776,\n",
       "        -0.33047417,  0.20484395,  0.02976446, -0.3235725 , -0.22644459],\n",
       "       [ 0.09975111,  0.4164229 , -0.05972092,  0.4724858 ,  0.07625274,\n",
       "        -0.37556273, -0.41675794,  0.1072961 , -0.22256404,  0.07434572],\n",
       "       [-0.33588484, -0.26314247,  0.48928934, -0.42041746,  0.49042416,\n",
       "        -0.07778177,  0.13300411,  0.34206462,  0.41866353,  0.38699016],\n",
       "       [ 0.25059113,  0.18620391,  0.01138588,  0.03915464, -0.4131867 ,\n",
       "        -0.11133797, -0.00348904,  0.08867157, -0.30682206,  0.0675555 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
