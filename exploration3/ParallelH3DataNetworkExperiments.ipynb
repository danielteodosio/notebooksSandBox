{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def carregar_pickle(nome_arquivo):\n",
    "  with open(nome_arquivo, 'rb') as arquivo:\n",
    "    objeto = pickle.load(arquivo)\n",
    "  return objeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando h3 w3_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set1 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_full1 = raw_data_set1['inputs']\n",
    "output_full1 = raw_data_set1['outputs']\n",
    "sequences_full1 = raw_data_set1['sequences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando h3 w12_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set2 = carregar_pickle('dataset_H3_W12S4.pkl')\n",
    "input_full2 = raw_data_set2['inputs']\n",
    "output_full2 = raw_data_set2['outputs']\n",
    "sequences_full2 = raw_data_set2['sequences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carregando multiplas representações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_setR0 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_fullR0 = raw_data_setR0['inputs']\n",
    "output_fullR0 = raw_data_setR0['outputs']\n",
    "sequences_fullR0 = raw_data_setR0['sequences']\n",
    "\n",
    "raw_data_setR1 = carregar_pickle('dataset_H3_W12S4.pkl')\n",
    "input_fullR1 = raw_data_setR1['inputs']\n",
    "output_fullR1 = raw_data_setR1['outputs']\n",
    "sequences_fullR1 = raw_data_setR1['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of difs: 0\n",
      "Ordem OK\n"
     ]
    }
   ],
   "source": [
    "validaSequencesOrder(sequences_fullR0, sequences_fullR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14963, 497, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fullR0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando datasets w3_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train1, input_test1, output_train1, output_test1, sequence_train1, sequence_test1 = train_test_split(input_full1, output_full1, \n",
    "sequences_full1, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando datasets w12_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train2, input_test2, output_train2, output_test2, sequence_train2, sequence_test2 = train_test_split(input_full2, output_full2, \n",
    "sequences_full2, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando dataset conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_trainR0, input_testR0, input_trainR1, input_testR1, output_trainConj, output_testConj, sequence_trainConj, sequence_testConj = train_test_split(input_fullR0, input_fullR1, output_fullR0, \n",
    "sequences_fullR0, train_size=0.75 , shuffle= True, random_state = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11222, 122, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_trainR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# binariza resultado da classificação da RN. \n",
    "#param: array -> Rn output, corte -> x > corte significa 1\n",
    "def myClassify(array, corte):\n",
    "    classifiedArray = []\n",
    "    for x in array:\n",
    "        if(x > corte):\n",
    "            classifiedArray.append(1)\n",
    "        else:\n",
    "            classifiedArray.append(0)\n",
    "    \n",
    "    return classifiedArray\n",
    "\n",
    "# Retorna lista com Ok/Nok para predição binarizada  e valor real\n",
    "# param: arrPredict -> predict da rede\n",
    "# param: arrReal -> valores reais de referência\n",
    "def comparePredictOkNok(arrPredict, arrReal):\n",
    "\n",
    "    sizePredict = len(arrPredict)\n",
    "    sizeArrReal = len(arrReal)\n",
    "\n",
    "    if(sizePredict != sizeArrReal):\n",
    "        print('tamanho dos arrays é imcompatível')\n",
    "        return\n",
    "\n",
    "    size = sizeArrReal\n",
    "\n",
    "    arrOkNok = []\n",
    "    for i in range(0, size):\n",
    "        if(arrPredict[i] == arrReal[i]):\n",
    "            arrOkNok.append('OK')\n",
    "        else:\n",
    "            arrOkNok.append('NOK')\n",
    "    \n",
    "    return arrOkNok\n",
    "\n",
    "\n",
    "\n",
    "# Retorna lista com Ok/Nok para predição binarizada  e valor real\n",
    "# param: arrPredict -> predict da rede\n",
    "# param: arrReal -> valores reais de referência\n",
    "# param: sequenceTest -> sequencia correspondente\n",
    "def comparePredictOkNokWithSeq(arrPredict, arrReal, sequenceTest):\n",
    "\n",
    "    sizePredict = len(arrPredict)\n",
    "    sizeArrReal = len(arrReal)\n",
    "\n",
    "    if(sizePredict != sizeArrReal):\n",
    "        print('tamanho dos arrays é imcompatível')\n",
    "        return\n",
    "\n",
    "    size = sizeArrReal\n",
    "\n",
    "    arrOkNok = []\n",
    "    for i in range(0, size):\n",
    "        if(arrPredict[i] == arrReal[i]):\n",
    "            arrOkNok.append('OK' + ' : ' + sequenceTest[i])\n",
    "        else:\n",
    "            arrOkNok.append('NOK' + ' : ' + sequenceTest[i])\n",
    "    \n",
    "    return arrOkNok\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyIfSeqWindowAndStrideMatches(seqSize, windowSize, strideSize):\n",
    "    last_window_start = 0\n",
    "    nOfStrides = 0\n",
    "    while (last_window_start + windowSize - 1) < (seqSize - 1):\n",
    "        last_window_start = strideSize * nOfStrides\n",
    "        nOfStrides = nOfStrides + 1\n",
    "        #print(last_window_start)\n",
    "        #print(nOfStrides)\n",
    "        #print(' ')\n",
    "\n",
    "    print('n of windows: ' + str(nOfStrides))\n",
    "    print('last window start: ' + str(last_window_start))\n",
    "    print('last window end: ' + str(last_window_start + windowSize - 1))\n",
    "    print('max seq position: ' + str(seqSize - 1))\n",
    "\n",
    "\n",
    "\n",
    "def validaSequencesOrder(seq0, seq1):\n",
    "    i = 0\n",
    "    d = 0\n",
    "    while i < len(seq0):\n",
    "        #print(seq0[i][0:15] + ' - ' + seq1[i][0:15])\n",
    "        if(seq0[i] != seq1[i]):\n",
    "            d = d+1\n",
    "        i = i + 1\n",
    "\n",
    "    if d > 0:\n",
    "        print('n of difs: ' + str(d))\n",
    "        print('Ordem NOK')\n",
    "    else:\n",
    "        print('n of difs: ' + str(d))\n",
    "        print('Ordem OK')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of windows: 7\n",
      "last window start: 30\n",
      "last window end: 37\n",
      "max seq position: 37\n"
     ]
    }
   ],
   "source": [
    "verifyIfSeqWindowAndStrideMatches(38,8,5)   # 38,8,5 -> 7    #163, 37, 21 => 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train1[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implementação funcional paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputR0 = keras.Input(shape=(497, 16)) \n",
    "conv1R0 = keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (497, 16), use_bias= True)(inputR0)\n",
    "pool1R0 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R0)\n",
    "conv2R0 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R0)\n",
    "pool2R0 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R0)\n",
    "#flatR0 = keras.layers.Flatten()(pool2R0)\n",
    "\n",
    "inputR1 = keras.Input(shape=(122, 52)) \n",
    "conv1R1 = keras.layers.Conv1D(5, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (122, 52), use_bias= True)(inputR1)\n",
    "pool1R1 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R1)\n",
    "conv2R1 = keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (38, 10), use_bias= True)(pool1R1)\n",
    "pool2R1 = keras.layers.AveragePooling1D(pool_size=8, strides= 5, padding='valid')(conv2R1)\n",
    "#flatR1 =  keras.layers.Flatten()(pool2R1)\n",
    "\n",
    "concatenate_filters = keras.layers.concatenate([pool2R0, pool2R1])\n",
    "\n",
    "convOut = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, \n",
    "                              padding='valid', activation='relu', use_bias= True)(concatenate_filters)\n",
    "\n",
    "poolOut = keras.layers.GlobalAveragePooling1D()(convOut)\n",
    "\n",
    "flatOut =  keras.layers.Flatten()(poolOut)\n",
    "\n",
    "dense1 = keras.layers.Dense(32, activation=keras.layers.LeakyReLU(alpha=0.3))(flatOut)  #keras.layers.LeakyReLU(alpha=0.3)\n",
    "dense2 = keras.layers.Dense(10, activation=keras.layers.LeakyReLU(alpha=0.3))(dense1)\n",
    "#dense3 = keras.layers.Dense(10, activation=keras.layers.LeakyReLU(alpha=0.3))(dense2)\n",
    "outpu1 = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "model = keras.Model(inputs= [inputR0, inputR1], outputs=outpu1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CNN = keras.Sequential()\n",
    "\n",
    "# CNN.add(keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (122, 52), use_bias= True))    #activation='relu'\n",
    "# CNN.add(keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid'))\n",
    "\n",
    "# CNN.add(keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', \n",
    "#                             activation='relu', input_shape = (38, 10), use_bias= True))\n",
    "# #CNN.add(keras.layers.AveragePooling1D(pool_size=8, strides= 5, padding='valid'))\n",
    "# CNN.add(keras.layers.GlobalAveragePooling1D())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 497, 16)]    0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 122, 52)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 497, 10)      170         ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 122, 5)       265         ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling1d_60 (AverageP  (None, 163, 10)     0           ['conv1d_75[0][0]']              \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling1d_62 (AverageP  (None, 38, 5)       0           ['conv1d_77[0][0]']              \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 163, 35)      385         ['average_pooling1d_60[0][0]']   \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 38, 10)       60          ['average_pooling1d_62[0][0]']   \n",
      "                                                                                                  \n",
      " average_pooling1d_61 (AverageP  (None, 7, 35)       0           ['conv1d_76[0][0]']              \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling1d_63 (AverageP  (None, 7, 10)       0           ['conv1d_78[0][0]']              \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 7, 45)        0           ['average_pooling1d_61[0][0]',   \n",
      "                                                                  'average_pooling1d_63[0][0]']   \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 7, 60)        2760        ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 60)          0           ['conv1d_79[0][0]']              \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 60)           0           ['global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 32)           1952        ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 10)           330         ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1)            11          ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,933\n",
      "Trainable params: 5,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();\n",
    "#keras.utils.plot_model(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implemetação paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(reduction='sum_over_batch_size'), metrics=['accuracy']\n",
    "            , optimizer= keras.optimizers.Adam(learning_rate=0.001))   #sum_over_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "211/211 [==============================] - 38s 170ms/step - loss: 0.6282 - accuracy: 0.6428 - val_loss: 0.5137 - val_accuracy: 0.7650\n",
      "Epoch 2/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.5021 - accuracy: 0.7564 - val_loss: 0.5389 - val_accuracy: 0.7262\n",
      "Epoch 3/500\n",
      "211/211 [==============================] - 33s 155ms/step - loss: 0.4825 - accuracy: 0.7705 - val_loss: 0.4865 - val_accuracy: 0.7701\n",
      "Epoch 4/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.4686 - accuracy: 0.7848 - val_loss: 0.4665 - val_accuracy: 0.7877\n",
      "Epoch 5/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.4601 - accuracy: 0.7913 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 6/500\n",
      "211/211 [==============================] - 30s 140ms/step - loss: 0.4480 - accuracy: 0.7976 - val_loss: 0.4611 - val_accuracy: 0.7884\n",
      "Epoch 7/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.4393 - accuracy: 0.8016 - val_loss: 0.4264 - val_accuracy: 0.8111\n",
      "Epoch 8/500\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.4243 - accuracy: 0.8069 - val_loss: 0.5024 - val_accuracy: 0.7594\n",
      "Epoch 9/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.4136 - accuracy: 0.8149 - val_loss: 0.4989 - val_accuracy: 0.7648\n",
      "Epoch 10/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.4113 - accuracy: 0.8164 - val_loss: 0.4278 - val_accuracy: 0.8138\n",
      "Epoch 11/500\n",
      "211/211 [==============================] - 33s 157ms/step - loss: 0.4029 - accuracy: 0.8215 - val_loss: 0.4147 - val_accuracy: 0.8169\n",
      "Epoch 12/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.3974 - accuracy: 0.8276 - val_loss: 0.4264 - val_accuracy: 0.8115\n",
      "Epoch 13/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.4071 - accuracy: 0.8218 - val_loss: 0.4101 - val_accuracy: 0.8245\n",
      "Epoch 14/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.3964 - accuracy: 0.8265 - val_loss: 0.3986 - val_accuracy: 0.8331\n",
      "Epoch 15/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3924 - accuracy: 0.8319 - val_loss: 0.3913 - val_accuracy: 0.8343\n",
      "Epoch 16/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3918 - accuracy: 0.8322 - val_loss: 0.3916 - val_accuracy: 0.8325\n",
      "Epoch 17/500\n",
      "211/211 [==============================] - 31s 149ms/step - loss: 0.3880 - accuracy: 0.8314 - val_loss: 0.3970 - val_accuracy: 0.8296\n",
      "Epoch 18/500\n",
      "211/211 [==============================] - 30s 142ms/step - loss: 0.3805 - accuracy: 0.8359 - val_loss: 0.4406 - val_accuracy: 0.8062\n",
      "Epoch 19/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3953 - accuracy: 0.8271 - val_loss: 0.4258 - val_accuracy: 0.8127\n",
      "Epoch 20/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3801 - accuracy: 0.8374 - val_loss: 0.4154 - val_accuracy: 0.8189\n",
      "Epoch 21/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3855 - accuracy: 0.8326 - val_loss: 0.3938 - val_accuracy: 0.8276\n",
      "Epoch 22/500\n",
      "211/211 [==============================] - 33s 157ms/step - loss: 0.3839 - accuracy: 0.8377 - val_loss: 0.3843 - val_accuracy: 0.8374\n",
      "Epoch 23/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.3742 - accuracy: 0.8408 - val_loss: 0.3999 - val_accuracy: 0.8329\n",
      "Epoch 24/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3807 - accuracy: 0.8386 - val_loss: 0.3861 - val_accuracy: 0.8325\n",
      "Epoch 25/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3747 - accuracy: 0.8390 - val_loss: 0.3834 - val_accuracy: 0.8398\n",
      "Epoch 26/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3766 - accuracy: 0.8381 - val_loss: 0.4089 - val_accuracy: 0.8247\n",
      "Epoch 27/500\n",
      "211/211 [==============================] - 29s 135ms/step - loss: 0.3765 - accuracy: 0.8359 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
      "Epoch 28/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.3722 - accuracy: 0.8408 - val_loss: 0.3829 - val_accuracy: 0.8389\n",
      "Epoch 29/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.3765 - accuracy: 0.8392 - val_loss: 0.3884 - val_accuracy: 0.8376\n",
      "Epoch 30/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3714 - accuracy: 0.8433 - val_loss: 0.4218 - val_accuracy: 0.8198\n",
      "Epoch 31/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3761 - accuracy: 0.8354 - val_loss: 0.3960 - val_accuracy: 0.8331\n",
      "Epoch 32/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3729 - accuracy: 0.8390 - val_loss: 0.3831 - val_accuracy: 0.8398\n",
      "Epoch 33/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.3737 - accuracy: 0.8412 - val_loss: 0.4377 - val_accuracy: 0.8100\n",
      "Epoch 34/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3683 - accuracy: 0.8442 - val_loss: 0.3781 - val_accuracy: 0.8429\n",
      "Epoch 35/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.3681 - accuracy: 0.8424 - val_loss: 0.4240 - val_accuracy: 0.8129\n",
      "Epoch 36/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3730 - accuracy: 0.8405 - val_loss: 0.3911 - val_accuracy: 0.8349\n",
      "Epoch 37/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3641 - accuracy: 0.8441 - val_loss: 0.3805 - val_accuracy: 0.8438\n",
      "Epoch 38/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3682 - accuracy: 0.8443 - val_loss: 0.4325 - val_accuracy: 0.8064\n",
      "Epoch 39/500\n",
      "211/211 [==============================] - 28s 135ms/step - loss: 0.3626 - accuracy: 0.8436 - val_loss: 0.3745 - val_accuracy: 0.8452\n",
      "Epoch 40/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3602 - accuracy: 0.8446 - val_loss: 0.3748 - val_accuracy: 0.8450\n",
      "Epoch 41/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3601 - accuracy: 0.8494 - val_loss: 0.3960 - val_accuracy: 0.8340\n",
      "Epoch 42/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.3653 - accuracy: 0.8442 - val_loss: 0.3855 - val_accuracy: 0.8396\n",
      "Epoch 43/500\n",
      "211/211 [==============================] - 28s 135ms/step - loss: 0.3623 - accuracy: 0.8487 - val_loss: 0.4099 - val_accuracy: 0.8196\n",
      "Epoch 44/500\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.3561 - accuracy: 0.8494 - val_loss: 0.3798 - val_accuracy: 0.8403\n",
      "Epoch 45/500\n",
      "211/211 [==============================] - 32s 149ms/step - loss: 0.3617 - accuracy: 0.8470 - val_loss: 0.3990 - val_accuracy: 0.8340\n",
      "Epoch 46/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3609 - accuracy: 0.8443 - val_loss: 0.3734 - val_accuracy: 0.8458\n",
      "Epoch 47/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.3568 - accuracy: 0.8498 - val_loss: 0.3744 - val_accuracy: 0.8452\n",
      "Epoch 48/500\n",
      "211/211 [==============================] - 31s 147ms/step - loss: 0.3589 - accuracy: 0.8457 - val_loss: 0.3765 - val_accuracy: 0.8429\n",
      "Epoch 49/500\n",
      "211/211 [==============================] - 26s 126ms/step - loss: 0.3563 - accuracy: 0.8515 - val_loss: 0.4022 - val_accuracy: 0.8298\n",
      "Epoch 50/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3519 - accuracy: 0.8516 - val_loss: 0.4133 - val_accuracy: 0.8240\n",
      "Epoch 51/500\n",
      "211/211 [==============================] - 33s 155ms/step - loss: 0.3566 - accuracy: 0.8473 - val_loss: 0.3803 - val_accuracy: 0.8454\n",
      "Epoch 52/500\n",
      "211/211 [==============================] - 37s 178ms/step - loss: 0.3591 - accuracy: 0.8498 - val_loss: 0.3972 - val_accuracy: 0.8296\n",
      "Epoch 53/500\n",
      "211/211 [==============================] - 28s 130ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.3834 - val_accuracy: 0.8369\n",
      "Epoch 54/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3545 - accuracy: 0.8464 - val_loss: 0.3754 - val_accuracy: 0.8450\n",
      "Epoch 55/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3516 - accuracy: 0.8501 - val_loss: 0.4128 - val_accuracy: 0.8193\n",
      "Epoch 56/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.3568 - accuracy: 0.8488 - val_loss: 0.3710 - val_accuracy: 0.8458\n",
      "Epoch 57/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.3536 - accuracy: 0.8470 - val_loss: 0.3874 - val_accuracy: 0.8323\n",
      "Epoch 58/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.3486 - accuracy: 0.8531 - val_loss: 0.3763 - val_accuracy: 0.8465\n",
      "Epoch 59/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3516 - accuracy: 0.8547 - val_loss: 0.3906 - val_accuracy: 0.8380\n",
      "Epoch 60/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3555 - accuracy: 0.8504 - val_loss: 0.3807 - val_accuracy: 0.8416\n",
      "Epoch 61/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.3463 - accuracy: 0.8534 - val_loss: 0.3722 - val_accuracy: 0.8479\n",
      "Epoch 62/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.3448 - accuracy: 0.8583 - val_loss: 0.3677 - val_accuracy: 0.8470\n",
      "Epoch 63/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3442 - accuracy: 0.8522 - val_loss: 0.3668 - val_accuracy: 0.8499\n",
      "Epoch 64/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.3417 - accuracy: 0.8610 - val_loss: 0.4164 - val_accuracy: 0.8240\n",
      "Epoch 65/500\n",
      "211/211 [==============================] - 30s 144ms/step - loss: 0.3423 - accuracy: 0.8579 - val_loss: 0.3992 - val_accuracy: 0.8276\n",
      "Epoch 66/500\n",
      "211/211 [==============================] - 46s 219ms/step - loss: 0.3430 - accuracy: 0.8565 - val_loss: 0.3705 - val_accuracy: 0.8443\n",
      "Epoch 67/500\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.3407 - accuracy: 0.8558 - val_loss: 0.3814 - val_accuracy: 0.8380\n",
      "Epoch 68/500\n",
      "211/211 [==============================] - 32s 152ms/step - loss: 0.3419 - accuracy: 0.8564 - val_loss: 0.3628 - val_accuracy: 0.8503\n",
      "Epoch 69/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3396 - accuracy: 0.8585 - val_loss: 0.3655 - val_accuracy: 0.8481\n",
      "Epoch 70/500\n",
      "211/211 [==============================] - 30s 144ms/step - loss: 0.3408 - accuracy: 0.8588 - val_loss: 0.3618 - val_accuracy: 0.8458\n",
      "Epoch 71/500\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.3368 - accuracy: 0.8579 - val_loss: 0.3866 - val_accuracy: 0.8387\n",
      "Epoch 72/500\n",
      "211/211 [==============================] - 29s 140ms/step - loss: 0.3410 - accuracy: 0.8574 - val_loss: 0.3810 - val_accuracy: 0.8387\n",
      "Epoch 73/500\n",
      "211/211 [==============================] - 28s 130ms/step - loss: 0.3332 - accuracy: 0.8586 - val_loss: 0.3698 - val_accuracy: 0.8465\n",
      "Epoch 74/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3359 - accuracy: 0.8585 - val_loss: 0.3653 - val_accuracy: 0.8492\n",
      "Epoch 75/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.3357 - accuracy: 0.8577 - val_loss: 0.3603 - val_accuracy: 0.8536\n",
      "Epoch 76/500\n",
      "211/211 [==============================] - 28s 135ms/step - loss: 0.3320 - accuracy: 0.8629 - val_loss: 0.3591 - val_accuracy: 0.8505\n",
      "Epoch 77/500\n",
      "211/211 [==============================] - 39s 183ms/step - loss: 0.3261 - accuracy: 0.8654 - val_loss: 0.3637 - val_accuracy: 0.8472\n",
      "Epoch 78/500\n",
      "211/211 [==============================] - 41s 194ms/step - loss: 0.3338 - accuracy: 0.8641 - val_loss: 0.3983 - val_accuracy: 0.8291\n",
      "Epoch 79/500\n",
      "211/211 [==============================] - 29s 140ms/step - loss: 0.3263 - accuracy: 0.8663 - val_loss: 0.3983 - val_accuracy: 0.8254\n",
      "Epoch 80/500\n",
      "211/211 [==============================] - 33s 158ms/step - loss: 0.3364 - accuracy: 0.8556 - val_loss: 0.3537 - val_accuracy: 0.8519\n",
      "Epoch 81/500\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.3298 - accuracy: 0.8629 - val_loss: 0.3579 - val_accuracy: 0.8487\n",
      "Epoch 82/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.3221 - accuracy: 0.8692 - val_loss: 0.3889 - val_accuracy: 0.8369\n",
      "Epoch 83/500\n",
      "211/211 [==============================] - 36s 170ms/step - loss: 0.3210 - accuracy: 0.8689 - val_loss: 0.3717 - val_accuracy: 0.8389\n",
      "Epoch 84/500\n",
      "211/211 [==============================] - 41s 197ms/step - loss: 0.3276 - accuracy: 0.8617 - val_loss: 0.3576 - val_accuracy: 0.8494\n",
      "Epoch 85/500\n",
      "211/211 [==============================] - 39s 184ms/step - loss: 0.3243 - accuracy: 0.8669 - val_loss: 0.3556 - val_accuracy: 0.8476\n",
      "Epoch 86/500\n",
      "211/211 [==============================] - 41s 196ms/step - loss: 0.3268 - accuracy: 0.8582 - val_loss: 0.3656 - val_accuracy: 0.8505\n",
      "Epoch 87/500\n",
      "211/211 [==============================] - 35s 164ms/step - loss: 0.3241 - accuracy: 0.8675 - val_loss: 0.3555 - val_accuracy: 0.8463\n",
      "Epoch 88/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.3262 - accuracy: 0.8632 - val_loss: 0.3700 - val_accuracy: 0.8427\n",
      "Epoch 89/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3197 - accuracy: 0.8689 - val_loss: 0.3579 - val_accuracy: 0.8474\n",
      "Epoch 90/500\n",
      "211/211 [==============================] - 35s 165ms/step - loss: 0.3170 - accuracy: 0.8705 - val_loss: 0.3647 - val_accuracy: 0.8436\n",
      "Epoch 91/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3197 - accuracy: 0.8645 - val_loss: 0.3577 - val_accuracy: 0.8505\n",
      "Epoch 92/500\n",
      "211/211 [==============================] - 34s 160ms/step - loss: 0.3207 - accuracy: 0.8681 - val_loss: 0.3467 - val_accuracy: 0.8534\n",
      "Epoch 93/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3224 - accuracy: 0.8640 - val_loss: 0.3766 - val_accuracy: 0.8407\n",
      "Epoch 94/500\n",
      "211/211 [==============================] - 30s 140ms/step - loss: 0.3161 - accuracy: 0.8690 - val_loss: 0.3519 - val_accuracy: 0.8512\n",
      "Epoch 95/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.3156 - accuracy: 0.8705 - val_loss: 0.3949 - val_accuracy: 0.8245\n",
      "Epoch 96/500\n",
      "211/211 [==============================] - 41s 194ms/step - loss: 0.3157 - accuracy: 0.8690 - val_loss: 0.3781 - val_accuracy: 0.8343\n",
      "Epoch 97/500\n",
      "211/211 [==============================] - 45s 213ms/step - loss: 0.3179 - accuracy: 0.8686 - val_loss: 0.3527 - val_accuracy: 0.8516\n",
      "Epoch 98/500\n",
      "211/211 [==============================] - 48s 229ms/step - loss: 0.3133 - accuracy: 0.8705 - val_loss: 0.3772 - val_accuracy: 0.8334\n",
      "Epoch 99/500\n",
      "211/211 [==============================] - 42s 198ms/step - loss: 0.3182 - accuracy: 0.8703 - val_loss: 0.3551 - val_accuracy: 0.8505\n",
      "Epoch 100/500\n",
      "211/211 [==============================] - 37s 174ms/step - loss: 0.3139 - accuracy: 0.8705 - val_loss: 0.3446 - val_accuracy: 0.8570\n",
      "Epoch 101/500\n",
      "211/211 [==============================] - 39s 183ms/step - loss: 0.3149 - accuracy: 0.8711 - val_loss: 0.3605 - val_accuracy: 0.8487\n",
      "Epoch 102/500\n",
      "211/211 [==============================] - 37s 176ms/step - loss: 0.3102 - accuracy: 0.8741 - val_loss: 0.3505 - val_accuracy: 0.8536\n",
      "Epoch 103/500\n",
      "211/211 [==============================] - 33s 159ms/step - loss: 0.3073 - accuracy: 0.8709 - val_loss: 0.3607 - val_accuracy: 0.8476\n",
      "Epoch 104/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.3156 - accuracy: 0.8700 - val_loss: 0.3570 - val_accuracy: 0.8496\n",
      "Epoch 105/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3124 - accuracy: 0.8692 - val_loss: 0.3494 - val_accuracy: 0.8512\n",
      "Epoch 106/500\n",
      "211/211 [==============================] - 31s 145ms/step - loss: 0.3144 - accuracy: 0.8726 - val_loss: 0.3529 - val_accuracy: 0.8521\n",
      "Epoch 107/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.3068 - accuracy: 0.8726 - val_loss: 0.3541 - val_accuracy: 0.8521\n",
      "Epoch 108/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.3096 - accuracy: 0.8726 - val_loss: 0.3461 - val_accuracy: 0.8545\n",
      "Epoch 109/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.3108 - accuracy: 0.8724 - val_loss: 0.3615 - val_accuracy: 0.8467\n",
      "Epoch 110/500\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.3084 - accuracy: 0.8715 - val_loss: 0.3497 - val_accuracy: 0.8583\n",
      "Epoch 111/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.3092 - accuracy: 0.8726 - val_loss: 0.3531 - val_accuracy: 0.8552\n",
      "Epoch 112/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.3495 - val_accuracy: 0.8556\n",
      "Epoch 113/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.3091 - accuracy: 0.8727 - val_loss: 0.3822 - val_accuracy: 0.8376\n",
      "Epoch 114/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.3062 - accuracy: 0.8758 - val_loss: 0.3820 - val_accuracy: 0.8378\n",
      "Epoch 115/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.3034 - accuracy: 0.8758 - val_loss: 0.3489 - val_accuracy: 0.8579\n",
      "Epoch 116/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.3064 - accuracy: 0.8721 - val_loss: 0.4096 - val_accuracy: 0.8238\n",
      "Epoch 117/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3101 - accuracy: 0.8738 - val_loss: 0.3822 - val_accuracy: 0.8398\n",
      "Epoch 118/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.3124 - accuracy: 0.8757 - val_loss: 0.3548 - val_accuracy: 0.8548\n",
      "Epoch 119/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.3044 - accuracy: 0.8758 - val_loss: 0.3729 - val_accuracy: 0.8331\n",
      "Epoch 120/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3042 - accuracy: 0.8749 - val_loss: 0.3788 - val_accuracy: 0.8416\n",
      "Epoch 121/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.3023 - accuracy: 0.8775 - val_loss: 0.3525 - val_accuracy: 0.8525\n",
      "Epoch 122/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3072 - accuracy: 0.8749 - val_loss: 0.3526 - val_accuracy: 0.8514\n",
      "Epoch 123/500\n",
      "211/211 [==============================] - 28s 135ms/step - loss: 0.3023 - accuracy: 0.8736 - val_loss: 0.3671 - val_accuracy: 0.8434\n",
      "Epoch 124/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.3039 - accuracy: 0.8744 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
      "Epoch 125/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.3075 - accuracy: 0.8700 - val_loss: 0.3622 - val_accuracy: 0.8454\n",
      "Epoch 126/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.3030 - accuracy: 0.8741 - val_loss: 0.3484 - val_accuracy: 0.8552\n",
      "Epoch 127/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.3005 - accuracy: 0.8769 - val_loss: 0.3461 - val_accuracy: 0.8534\n",
      "Epoch 128/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.3047 - accuracy: 0.8742 - val_loss: 0.3471 - val_accuracy: 0.8561\n",
      "Epoch 129/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.3007 - accuracy: 0.8790 - val_loss: 0.3506 - val_accuracy: 0.8539\n",
      "Epoch 130/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3018 - accuracy: 0.8769 - val_loss: 0.3429 - val_accuracy: 0.8608\n",
      "Epoch 131/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.3004 - accuracy: 0.8748 - val_loss: 0.3569 - val_accuracy: 0.8521\n",
      "Epoch 132/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.2946 - accuracy: 0.8793 - val_loss: 0.3486 - val_accuracy: 0.8521\n",
      "Epoch 133/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2956 - accuracy: 0.8791 - val_loss: 0.3514 - val_accuracy: 0.8534\n",
      "Epoch 134/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2940 - accuracy: 0.8775 - val_loss: 0.3546 - val_accuracy: 0.8554\n",
      "Epoch 135/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2970 - accuracy: 0.8797 - val_loss: 0.3738 - val_accuracy: 0.8447\n",
      "Epoch 136/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.3013 - accuracy: 0.8758 - val_loss: 0.3514 - val_accuracy: 0.8503\n",
      "Epoch 137/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2989 - accuracy: 0.8785 - val_loss: 0.3439 - val_accuracy: 0.8572\n",
      "Epoch 138/500\n",
      "211/211 [==============================] - 27s 125ms/step - loss: 0.2953 - accuracy: 0.8787 - val_loss: 0.3570 - val_accuracy: 0.8541\n",
      "Epoch 139/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2967 - accuracy: 0.8751 - val_loss: 0.3679 - val_accuracy: 0.8479\n",
      "Epoch 140/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2961 - accuracy: 0.8800 - val_loss: 0.3445 - val_accuracy: 0.8570\n",
      "Epoch 141/500\n",
      "211/211 [==============================] - 31s 147ms/step - loss: 0.2917 - accuracy: 0.8828 - val_loss: 0.3480 - val_accuracy: 0.8579\n",
      "Epoch 142/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2953 - accuracy: 0.8782 - val_loss: 0.3474 - val_accuracy: 0.8568\n",
      "Epoch 143/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.2920 - accuracy: 0.8833 - val_loss: 0.3448 - val_accuracy: 0.8585\n",
      "Epoch 144/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2986 - accuracy: 0.8778 - val_loss: 0.3468 - val_accuracy: 0.8570\n",
      "Epoch 145/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.2894 - accuracy: 0.8815 - val_loss: 0.3587 - val_accuracy: 0.8407\n",
      "Epoch 146/500\n",
      "211/211 [==============================] - 28s 130ms/step - loss: 0.2920 - accuracy: 0.8776 - val_loss: 0.3751 - val_accuracy: 0.8398\n",
      "Epoch 147/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2876 - accuracy: 0.8840 - val_loss: 0.3585 - val_accuracy: 0.8472\n",
      "Epoch 148/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2905 - accuracy: 0.8822 - val_loss: 0.3551 - val_accuracy: 0.8559\n",
      "Epoch 149/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2887 - accuracy: 0.8827 - val_loss: 0.3803 - val_accuracy: 0.8363\n",
      "Epoch 150/500\n",
      "211/211 [==============================] - 27s 125ms/step - loss: 0.2867 - accuracy: 0.8816 - val_loss: 0.3519 - val_accuracy: 0.8563\n",
      "Epoch 151/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2869 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8516\n",
      "Epoch 152/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2866 - accuracy: 0.8810 - val_loss: 0.3699 - val_accuracy: 0.8416\n",
      "Epoch 153/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.2906 - accuracy: 0.8819 - val_loss: 0.3679 - val_accuracy: 0.8494\n",
      "Epoch 154/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.2856 - accuracy: 0.8821 - val_loss: 0.3541 - val_accuracy: 0.8552\n",
      "Epoch 155/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.2819 - accuracy: 0.8880 - val_loss: 0.3850 - val_accuracy: 0.8392\n",
      "Epoch 156/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2960 - accuracy: 0.8787 - val_loss: 0.4040 - val_accuracy: 0.8309\n",
      "Epoch 157/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2918 - accuracy: 0.8785 - val_loss: 0.3633 - val_accuracy: 0.8487\n",
      "Epoch 158/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2861 - accuracy: 0.8836 - val_loss: 0.3571 - val_accuracy: 0.8556\n",
      "Epoch 159/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2869 - accuracy: 0.8815 - val_loss: 0.3616 - val_accuracy: 0.8463\n",
      "Epoch 160/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2873 - accuracy: 0.8810 - val_loss: 0.3653 - val_accuracy: 0.8525\n",
      "Epoch 161/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.2863 - accuracy: 0.8834 - val_loss: 0.3795 - val_accuracy: 0.8356\n",
      "Epoch 162/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2785 - accuracy: 0.8850 - val_loss: 0.3658 - val_accuracy: 0.8519\n",
      "Epoch 163/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2811 - accuracy: 0.8833 - val_loss: 0.3546 - val_accuracy: 0.8563\n",
      "Epoch 164/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2792 - accuracy: 0.8849 - val_loss: 0.3611 - val_accuracy: 0.8559\n",
      "Epoch 165/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2787 - accuracy: 0.8862 - val_loss: 0.3751 - val_accuracy: 0.8416\n",
      "Epoch 166/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2776 - accuracy: 0.8891 - val_loss: 0.3475 - val_accuracy: 0.8619\n",
      "Epoch 167/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.2805 - accuracy: 0.8880 - val_loss: 0.3548 - val_accuracy: 0.8523\n",
      "Epoch 168/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2767 - accuracy: 0.8865 - val_loss: 0.3759 - val_accuracy: 0.8492\n",
      "Epoch 169/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.2801 - accuracy: 0.8847 - val_loss: 0.3843 - val_accuracy: 0.8396\n",
      "Epoch 170/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2827 - accuracy: 0.8864 - val_loss: 0.3669 - val_accuracy: 0.8447\n",
      "Epoch 171/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2765 - accuracy: 0.8856 - val_loss: 0.3844 - val_accuracy: 0.8331\n",
      "Epoch 172/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.2792 - accuracy: 0.8870 - val_loss: 0.3570 - val_accuracy: 0.8496\n",
      "Epoch 173/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2757 - accuracy: 0.8873 - val_loss: 0.3761 - val_accuracy: 0.8479\n",
      "Epoch 174/500\n",
      "211/211 [==============================] - 36s 170ms/step - loss: 0.2769 - accuracy: 0.8864 - val_loss: 0.3576 - val_accuracy: 0.8528\n",
      "Epoch 175/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.2750 - accuracy: 0.8883 - val_loss: 0.3729 - val_accuracy: 0.8470\n",
      "Epoch 176/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2776 - accuracy: 0.8888 - val_loss: 0.3615 - val_accuracy: 0.8514\n",
      "Epoch 177/500\n",
      "211/211 [==============================] - 32s 151ms/step - loss: 0.2715 - accuracy: 0.8908 - val_loss: 0.3629 - val_accuracy: 0.8570\n",
      "Epoch 178/500\n",
      "211/211 [==============================] - 39s 186ms/step - loss: 0.2724 - accuracy: 0.8892 - val_loss: 0.3580 - val_accuracy: 0.8523\n",
      "Epoch 179/500\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.2758 - accuracy: 0.8914 - val_loss: 0.3746 - val_accuracy: 0.8476\n",
      "Epoch 180/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.2688 - accuracy: 0.8914 - val_loss: 0.3953 - val_accuracy: 0.8349\n",
      "Epoch 181/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2705 - accuracy: 0.8904 - val_loss: 0.3702 - val_accuracy: 0.8568\n",
      "Epoch 182/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.2714 - accuracy: 0.8867 - val_loss: 0.3614 - val_accuracy: 0.8536\n",
      "Epoch 183/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2708 - accuracy: 0.8905 - val_loss: 0.3685 - val_accuracy: 0.8487\n",
      "Epoch 184/500\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.2701 - accuracy: 0.8894 - val_loss: 0.4047 - val_accuracy: 0.8311\n",
      "Epoch 185/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2723 - accuracy: 0.8877 - val_loss: 0.3674 - val_accuracy: 0.8496\n",
      "Epoch 186/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2680 - accuracy: 0.8913 - val_loss: 0.3658 - val_accuracy: 0.8534\n",
      "Epoch 187/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2696 - accuracy: 0.8919 - val_loss: 0.3750 - val_accuracy: 0.8443\n",
      "Epoch 188/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.2678 - accuracy: 0.8908 - val_loss: 0.4301 - val_accuracy: 0.8256\n",
      "Epoch 189/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2687 - accuracy: 0.8916 - val_loss: 0.4077 - val_accuracy: 0.8447\n",
      "Epoch 190/500\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.2691 - accuracy: 0.8899 - val_loss: 0.3722 - val_accuracy: 0.8525\n",
      "Epoch 191/500\n",
      "211/211 [==============================] - 28s 135ms/step - loss: 0.2665 - accuracy: 0.8905 - val_loss: 0.3685 - val_accuracy: 0.8532\n",
      "Epoch 192/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.2777 - accuracy: 0.8844 - val_loss: 0.4215 - val_accuracy: 0.8238\n",
      "Epoch 193/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2678 - accuracy: 0.8925 - val_loss: 0.3826 - val_accuracy: 0.8503\n",
      "Epoch 194/500\n",
      "211/211 [==============================] - 26s 126ms/step - loss: 0.2661 - accuracy: 0.8907 - val_loss: 0.4019 - val_accuracy: 0.8418\n",
      "Epoch 195/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2609 - accuracy: 0.8959 - val_loss: 0.3843 - val_accuracy: 0.8490\n",
      "Epoch 196/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2697 - accuracy: 0.8911 - val_loss: 0.3713 - val_accuracy: 0.8554\n",
      "Epoch 197/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2644 - accuracy: 0.8950 - val_loss: 0.3745 - val_accuracy: 0.8479\n",
      "Epoch 198/500\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.2622 - accuracy: 0.8954 - val_loss: 0.3773 - val_accuracy: 0.8450\n",
      "Epoch 199/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2632 - accuracy: 0.8902 - val_loss: 0.3803 - val_accuracy: 0.8541\n",
      "Epoch 200/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.2587 - accuracy: 0.8950 - val_loss: 0.3681 - val_accuracy: 0.8519\n",
      "Epoch 201/500\n",
      "211/211 [==============================] - 30s 143ms/step - loss: 0.2631 - accuracy: 0.8917 - val_loss: 0.3727 - val_accuracy: 0.8530\n",
      "Epoch 202/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2668 - accuracy: 0.8913 - val_loss: 0.3721 - val_accuracy: 0.8514\n",
      "Epoch 203/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2569 - accuracy: 0.8980 - val_loss: 0.3857 - val_accuracy: 0.8516\n",
      "Epoch 204/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2576 - accuracy: 0.8922 - val_loss: 0.3950 - val_accuracy: 0.8461\n",
      "Epoch 205/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.2580 - accuracy: 0.8959 - val_loss: 0.3897 - val_accuracy: 0.8409\n",
      "Epoch 206/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2641 - accuracy: 0.8937 - val_loss: 0.4161 - val_accuracy: 0.8396\n",
      "Epoch 207/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2585 - accuracy: 0.8957 - val_loss: 0.3843 - val_accuracy: 0.8501\n",
      "Epoch 208/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2654 - accuracy: 0.8947 - val_loss: 0.4499 - val_accuracy: 0.8155\n",
      "Epoch 209/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2616 - accuracy: 0.8975 - val_loss: 0.3929 - val_accuracy: 0.8429\n",
      "Epoch 210/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2571 - accuracy: 0.8931 - val_loss: 0.3958 - val_accuracy: 0.8454\n",
      "Epoch 211/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.2589 - accuracy: 0.8956 - val_loss: 0.4181 - val_accuracy: 0.8300\n",
      "Epoch 212/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.2582 - accuracy: 0.8934 - val_loss: 0.3851 - val_accuracy: 0.8465\n",
      "Epoch 213/500\n",
      "211/211 [==============================] - 31s 149ms/step - loss: 0.2549 - accuracy: 0.8968 - val_loss: 0.3862 - val_accuracy: 0.8490\n",
      "Epoch 214/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2571 - accuracy: 0.8960 - val_loss: 0.3883 - val_accuracy: 0.8398\n",
      "Epoch 215/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2491 - accuracy: 0.9017 - val_loss: 0.4058 - val_accuracy: 0.8387\n",
      "Epoch 216/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.2522 - accuracy: 0.8984 - val_loss: 0.3828 - val_accuracy: 0.8490\n",
      "Epoch 217/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.2529 - accuracy: 0.8995 - val_loss: 0.3957 - val_accuracy: 0.8418\n",
      "Epoch 218/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2458 - accuracy: 0.9033 - val_loss: 0.4253 - val_accuracy: 0.8358\n",
      "Epoch 219/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.2484 - accuracy: 0.8963 - val_loss: 0.3987 - val_accuracy: 0.8394\n",
      "Epoch 220/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.2576 - accuracy: 0.8947 - val_loss: 0.4103 - val_accuracy: 0.8414\n",
      "Epoch 221/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.2466 - accuracy: 0.9014 - val_loss: 0.4296 - val_accuracy: 0.8367\n",
      "Epoch 222/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.2656 - accuracy: 0.8945 - val_loss: 0.3906 - val_accuracy: 0.8394\n",
      "Epoch 223/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.2504 - accuracy: 0.8981 - val_loss: 0.3791 - val_accuracy: 0.8494\n",
      "Epoch 224/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2443 - accuracy: 0.9064 - val_loss: 0.3940 - val_accuracy: 0.8438\n",
      "Epoch 225/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2509 - accuracy: 0.8968 - val_loss: 0.4008 - val_accuracy: 0.8496\n",
      "Epoch 226/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2500 - accuracy: 0.8960 - val_loss: 0.3915 - val_accuracy: 0.8490\n",
      "Epoch 227/500\n",
      "211/211 [==============================] - 44s 207ms/step - loss: 0.2466 - accuracy: 0.8999 - val_loss: 0.4091 - val_accuracy: 0.8403\n",
      "Epoch 228/500\n",
      "211/211 [==============================] - 39s 183ms/step - loss: 0.2479 - accuracy: 0.9018 - val_loss: 0.4029 - val_accuracy: 0.8447\n",
      "Epoch 229/500\n",
      "211/211 [==============================] - 37s 174ms/step - loss: 0.2461 - accuracy: 0.9023 - val_loss: 0.3945 - val_accuracy: 0.8485\n",
      "Epoch 230/500\n",
      "211/211 [==============================] - 42s 199ms/step - loss: 0.2481 - accuracy: 0.9026 - val_loss: 0.4103 - val_accuracy: 0.8363\n",
      "Epoch 231/500\n",
      "211/211 [==============================] - 39s 186ms/step - loss: 0.2427 - accuracy: 0.9049 - val_loss: 0.4030 - val_accuracy: 0.8472\n",
      "Epoch 232/500\n",
      "211/211 [==============================] - 42s 201ms/step - loss: 0.2493 - accuracy: 0.8963 - val_loss: 0.3913 - val_accuracy: 0.8505\n",
      "Epoch 233/500\n",
      "211/211 [==============================] - 44s 207ms/step - loss: 0.2433 - accuracy: 0.9023 - val_loss: 0.4178 - val_accuracy: 0.8403\n",
      "Epoch 234/500\n",
      "211/211 [==============================] - 32s 148ms/step - loss: 0.2434 - accuracy: 0.9026 - val_loss: 0.3981 - val_accuracy: 0.8447\n",
      "Epoch 235/500\n",
      "211/211 [==============================] - 27s 122ms/step - loss: 0.2416 - accuracy: 0.9035 - val_loss: 0.3935 - val_accuracy: 0.8485\n",
      "Epoch 236/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.2389 - accuracy: 0.9038 - val_loss: 0.4355 - val_accuracy: 0.8347\n",
      "Epoch 237/500\n",
      "211/211 [==============================] - 32s 152ms/step - loss: 0.2466 - accuracy: 0.9017 - val_loss: 0.3955 - val_accuracy: 0.8496\n",
      "Epoch 238/500\n",
      "211/211 [==============================] - 31s 149ms/step - loss: 0.2383 - accuracy: 0.9058 - val_loss: 0.4363 - val_accuracy: 0.8311\n",
      "Epoch 239/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2414 - accuracy: 0.9021 - val_loss: 0.4003 - val_accuracy: 0.8487\n",
      "Epoch 240/500\n",
      "211/211 [==============================] - 30s 143ms/step - loss: 0.2455 - accuracy: 0.8987 - val_loss: 0.4386 - val_accuracy: 0.8323\n",
      "Epoch 241/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.2385 - accuracy: 0.9070 - val_loss: 0.4056 - val_accuracy: 0.8476\n",
      "Epoch 242/500\n",
      "211/211 [==============================] - 31s 148ms/step - loss: 0.2369 - accuracy: 0.9064 - val_loss: 0.4075 - val_accuracy: 0.8427\n",
      "Epoch 243/500\n",
      "211/211 [==============================] - 32s 151ms/step - loss: 0.2466 - accuracy: 0.9020 - val_loss: 0.4366 - val_accuracy: 0.8334\n",
      "Epoch 244/500\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.2366 - accuracy: 0.9085 - val_loss: 0.4448 - val_accuracy: 0.8418\n",
      "Epoch 245/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.2404 - accuracy: 0.9014 - val_loss: 0.4264 - val_accuracy: 0.8403\n",
      "Epoch 246/500\n",
      "211/211 [==============================] - 29s 135ms/step - loss: 0.2375 - accuracy: 0.9072 - val_loss: 0.4197 - val_accuracy: 0.8367\n",
      "Epoch 247/500\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.2343 - accuracy: 0.9072 - val_loss: 0.4304 - val_accuracy: 0.8387\n",
      "Epoch 248/500\n",
      "211/211 [==============================] - 31s 145ms/step - loss: 0.2311 - accuracy: 0.9091 - val_loss: 0.4082 - val_accuracy: 0.8463\n",
      "Epoch 249/500\n",
      "211/211 [==============================] - 31s 147ms/step - loss: 0.2407 - accuracy: 0.9029 - val_loss: 0.4003 - val_accuracy: 0.8438\n",
      "Epoch 250/500\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.2408 - accuracy: 0.9070 - val_loss: 0.4383 - val_accuracy: 0.8331\n",
      "Epoch 251/500\n",
      "211/211 [==============================] - 36s 171ms/step - loss: 0.2322 - accuracy: 0.9070 - val_loss: 0.4251 - val_accuracy: 0.8358\n",
      "Epoch 252/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.2348 - accuracy: 0.9063 - val_loss: 0.4248 - val_accuracy: 0.8443\n",
      "Epoch 253/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.2340 - accuracy: 0.9058 - val_loss: 0.4082 - val_accuracy: 0.8369\n",
      "Epoch 254/500\n",
      "211/211 [==============================] - 42s 201ms/step - loss: 0.2377 - accuracy: 0.9084 - val_loss: 0.4425 - val_accuracy: 0.8309\n",
      "Epoch 255/500\n",
      "211/211 [==============================] - 37s 175ms/step - loss: 0.2290 - accuracy: 0.9124 - val_loss: 0.4336 - val_accuracy: 0.8380\n",
      "Epoch 256/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.2292 - accuracy: 0.9104 - val_loss: 0.4189 - val_accuracy: 0.8461\n",
      "Epoch 257/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.2314 - accuracy: 0.9075 - val_loss: 0.4256 - val_accuracy: 0.8356\n",
      "Epoch 258/500\n",
      "211/211 [==============================] - 37s 175ms/step - loss: 0.2311 - accuracy: 0.9088 - val_loss: 0.4163 - val_accuracy: 0.8476\n",
      "Epoch 259/500\n",
      "211/211 [==============================] - 38s 181ms/step - loss: 0.2365 - accuracy: 0.9075 - val_loss: 0.4253 - val_accuracy: 0.8409\n",
      "Epoch 260/500\n",
      "211/211 [==============================] - 36s 172ms/step - loss: 0.2242 - accuracy: 0.9145 - val_loss: 0.4122 - val_accuracy: 0.8432\n",
      "Epoch 261/500\n",
      "211/211 [==============================] - 39s 184ms/step - loss: 0.2266 - accuracy: 0.9097 - val_loss: 0.4521 - val_accuracy: 0.8307\n",
      "Epoch 262/500\n",
      "211/211 [==============================] - 36s 173ms/step - loss: 0.2301 - accuracy: 0.9082 - val_loss: 0.4257 - val_accuracy: 0.8396\n",
      "Epoch 263/500\n",
      "211/211 [==============================] - 50s 236ms/step - loss: 0.2314 - accuracy: 0.9075 - val_loss: 0.4653 - val_accuracy: 0.8311\n",
      "Epoch 264/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.2295 - accuracy: 0.9106 - val_loss: 0.4277 - val_accuracy: 0.8434\n",
      "Epoch 265/500\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.2207 - accuracy: 0.9136 - val_loss: 0.4388 - val_accuracy: 0.8414\n",
      "Epoch 266/500\n",
      "211/211 [==============================] - 36s 171ms/step - loss: 0.2216 - accuracy: 0.9145 - val_loss: 0.4428 - val_accuracy: 0.8412\n",
      "Epoch 267/500\n",
      "211/211 [==============================] - 36s 168ms/step - loss: 0.2318 - accuracy: 0.9095 - val_loss: 0.4100 - val_accuracy: 0.8463\n",
      "Epoch 268/500\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.2292 - accuracy: 0.9093 - val_loss: 0.4226 - val_accuracy: 0.8394\n",
      "Epoch 269/500\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.2221 - accuracy: 0.9133 - val_loss: 0.4215 - val_accuracy: 0.8516\n",
      "Epoch 270/500\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 0.2320 - accuracy: 0.9078 - val_loss: 0.4944 - val_accuracy: 0.8276\n",
      "Epoch 271/500\n",
      "211/211 [==============================] - 31s 145ms/step - loss: 0.2228 - accuracy: 0.9121 - val_loss: 0.4461 - val_accuracy: 0.8374\n",
      "Epoch 272/500\n",
      "211/211 [==============================] - 30s 140ms/step - loss: 0.2202 - accuracy: 0.9146 - val_loss: 0.4319 - val_accuracy: 0.8401\n",
      "Epoch 273/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2256 - accuracy: 0.9085 - val_loss: 0.4340 - val_accuracy: 0.8429\n",
      "Epoch 274/500\n",
      "211/211 [==============================] - 35s 166ms/step - loss: 0.2231 - accuracy: 0.9134 - val_loss: 0.4280 - val_accuracy: 0.8479\n",
      "Epoch 275/500\n",
      "211/211 [==============================] - 30s 144ms/step - loss: 0.2238 - accuracy: 0.9146 - val_loss: 0.4300 - val_accuracy: 0.8427\n",
      "Epoch 276/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2179 - accuracy: 0.9147 - val_loss: 0.4545 - val_accuracy: 0.8334\n",
      "Epoch 277/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.2188 - accuracy: 0.9155 - val_loss: 0.4615 - val_accuracy: 0.8358\n",
      "Epoch 278/500\n",
      "211/211 [==============================] - 33s 155ms/step - loss: 0.2307 - accuracy: 0.9079 - val_loss: 0.4534 - val_accuracy: 0.8409\n",
      "Epoch 279/500\n",
      "211/211 [==============================] - 38s 180ms/step - loss: 0.2213 - accuracy: 0.9140 - val_loss: 0.4649 - val_accuracy: 0.8334\n",
      "Epoch 280/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.2297 - accuracy: 0.9066 - val_loss: 0.4577 - val_accuracy: 0.8360\n",
      "Epoch 281/500\n",
      "211/211 [==============================] - 41s 196ms/step - loss: 0.2204 - accuracy: 0.9170 - val_loss: 0.4570 - val_accuracy: 0.8360\n",
      "Epoch 282/500\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.2167 - accuracy: 0.9165 - val_loss: 0.4462 - val_accuracy: 0.8418\n",
      "Epoch 283/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.2231 - accuracy: 0.9116 - val_loss: 0.4450 - val_accuracy: 0.8454\n",
      "Epoch 284/500\n",
      "211/211 [==============================] - 36s 172ms/step - loss: 0.2142 - accuracy: 0.9164 - val_loss: 0.4837 - val_accuracy: 0.8347\n",
      "Epoch 285/500\n",
      "211/211 [==============================] - 29s 137ms/step - loss: 0.2182 - accuracy: 0.9171 - val_loss: 0.4601 - val_accuracy: 0.8358\n",
      "Epoch 286/500\n",
      "211/211 [==============================] - 35s 166ms/step - loss: 0.2212 - accuracy: 0.9137 - val_loss: 0.4433 - val_accuracy: 0.8367\n",
      "Epoch 287/500\n",
      "211/211 [==============================] - 38s 179ms/step - loss: 0.2143 - accuracy: 0.9153 - val_loss: 0.4787 - val_accuracy: 0.8285\n",
      "Epoch 288/500\n",
      "211/211 [==============================] - 34s 161ms/step - loss: 0.2172 - accuracy: 0.9137 - val_loss: 0.4732 - val_accuracy: 0.8345\n",
      "Epoch 289/500\n",
      "211/211 [==============================] - 29s 135ms/step - loss: 0.2181 - accuracy: 0.9134 - val_loss: 0.4563 - val_accuracy: 0.8474\n",
      "Epoch 290/500\n",
      "211/211 [==============================] - 36s 170ms/step - loss: 0.2092 - accuracy: 0.9174 - val_loss: 0.4783 - val_accuracy: 0.8387\n",
      "Epoch 291/500\n",
      "211/211 [==============================] - 33s 156ms/step - loss: 0.2265 - accuracy: 0.9109 - val_loss: 0.4616 - val_accuracy: 0.8392\n",
      "Epoch 292/500\n",
      "211/211 [==============================] - 34s 160ms/step - loss: 0.2172 - accuracy: 0.9142 - val_loss: 0.4794 - val_accuracy: 0.8254\n",
      "Epoch 293/500\n",
      "211/211 [==============================] - 35s 166ms/step - loss: 0.2098 - accuracy: 0.9191 - val_loss: 0.4647 - val_accuracy: 0.8354\n",
      "Epoch 294/500\n",
      "211/211 [==============================] - 35s 164ms/step - loss: 0.2029 - accuracy: 0.9207 - val_loss: 0.4765 - val_accuracy: 0.8325\n",
      "Epoch 295/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.2146 - accuracy: 0.9165 - val_loss: 0.4596 - val_accuracy: 0.8418\n",
      "Epoch 296/500\n",
      "211/211 [==============================] - 39s 185ms/step - loss: 0.2213 - accuracy: 0.9136 - val_loss: 0.4607 - val_accuracy: 0.8354\n",
      "Epoch 297/500\n",
      "211/211 [==============================] - 37s 176ms/step - loss: 0.2115 - accuracy: 0.9161 - val_loss: 0.4788 - val_accuracy: 0.8349\n",
      "Epoch 298/500\n",
      "211/211 [==============================] - 33s 157ms/step - loss: 0.2076 - accuracy: 0.9201 - val_loss: 0.4795 - val_accuracy: 0.8329\n",
      "Epoch 299/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.2060 - accuracy: 0.9173 - val_loss: 0.5380 - val_accuracy: 0.8122\n",
      "Epoch 300/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.2111 - accuracy: 0.9162 - val_loss: 0.4899 - val_accuracy: 0.8320\n",
      "Epoch 301/500\n",
      "211/211 [==============================] - 35s 167ms/step - loss: 0.2055 - accuracy: 0.9173 - val_loss: 0.4718 - val_accuracy: 0.8367\n",
      "Epoch 302/500\n",
      "211/211 [==============================] - 33s 154ms/step - loss: 0.2022 - accuracy: 0.9222 - val_loss: 0.4913 - val_accuracy: 0.8340\n",
      "Epoch 303/500\n",
      "211/211 [==============================] - 33s 158ms/step - loss: 0.2116 - accuracy: 0.9199 - val_loss: 0.4736 - val_accuracy: 0.8380\n",
      "Epoch 304/500\n",
      "211/211 [==============================] - 30s 140ms/step - loss: 0.2029 - accuracy: 0.9223 - val_loss: 0.4838 - val_accuracy: 0.8369\n",
      "Epoch 305/500\n",
      "211/211 [==============================] - 30s 144ms/step - loss: 0.2117 - accuracy: 0.9192 - val_loss: 0.4962 - val_accuracy: 0.8287\n",
      "Epoch 306/500\n",
      "211/211 [==============================] - 37s 173ms/step - loss: 0.2054 - accuracy: 0.9189 - val_loss: 0.4919 - val_accuracy: 0.8349\n",
      "Epoch 307/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.2027 - accuracy: 0.9222 - val_loss: 0.4580 - val_accuracy: 0.8436\n",
      "Epoch 308/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.1980 - accuracy: 0.9217 - val_loss: 0.4788 - val_accuracy: 0.8385\n",
      "Epoch 309/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.2039 - accuracy: 0.9194 - val_loss: 0.5034 - val_accuracy: 0.8347\n",
      "Epoch 310/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.2092 - accuracy: 0.9165 - val_loss: 0.4792 - val_accuracy: 0.8407\n",
      "Epoch 311/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.2013 - accuracy: 0.9220 - val_loss: 0.4660 - val_accuracy: 0.8376\n",
      "Epoch 312/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.2050 - accuracy: 0.9180 - val_loss: 0.5274 - val_accuracy: 0.8147\n",
      "Epoch 313/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.2014 - accuracy: 0.9211 - val_loss: 0.5289 - val_accuracy: 0.8294\n",
      "Epoch 314/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.5095 - val_accuracy: 0.8320\n",
      "Epoch 315/500\n",
      "211/211 [==============================] - 27s 130ms/step - loss: 0.1981 - accuracy: 0.9229 - val_loss: 0.4732 - val_accuracy: 0.8356\n",
      "Epoch 316/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.4836 - val_accuracy: 0.8365\n",
      "Epoch 317/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1923 - accuracy: 0.9257 - val_loss: 0.5076 - val_accuracy: 0.8196\n",
      "Epoch 318/500\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.1978 - accuracy: 0.9234 - val_loss: 0.5244 - val_accuracy: 0.8254\n",
      "Epoch 319/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1975 - accuracy: 0.9214 - val_loss: 0.4906 - val_accuracy: 0.8396\n",
      "Epoch 320/500\n",
      "211/211 [==============================] - 24s 112ms/step - loss: 0.1979 - accuracy: 0.9210 - val_loss: 0.5364 - val_accuracy: 0.8305\n",
      "Epoch 321/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1960 - accuracy: 0.9229 - val_loss: 0.5214 - val_accuracy: 0.8345\n",
      "Epoch 322/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.1979 - accuracy: 0.9216 - val_loss: 0.4948 - val_accuracy: 0.8378\n",
      "Epoch 323/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1943 - accuracy: 0.9256 - val_loss: 0.4980 - val_accuracy: 0.8311\n",
      "Epoch 324/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1963 - accuracy: 0.9269 - val_loss: 0.4925 - val_accuracy: 0.8367\n",
      "Epoch 325/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1978 - accuracy: 0.9228 - val_loss: 0.4979 - val_accuracy: 0.8345\n",
      "Epoch 326/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1923 - accuracy: 0.9246 - val_loss: 0.5023 - val_accuracy: 0.8307\n",
      "Epoch 327/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.1908 - accuracy: 0.9229 - val_loss: 0.5091 - val_accuracy: 0.8320\n",
      "Epoch 328/500\n",
      "211/211 [==============================] - 30s 142ms/step - loss: 0.2009 - accuracy: 0.9222 - val_loss: 0.5076 - val_accuracy: 0.8352\n",
      "Epoch 329/500\n",
      "211/211 [==============================] - 37s 174ms/step - loss: 0.1950 - accuracy: 0.9205 - val_loss: 0.5273 - val_accuracy: 0.8300\n",
      "Epoch 330/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1921 - accuracy: 0.9231 - val_loss: 0.5144 - val_accuracy: 0.8314\n",
      "Epoch 331/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1895 - accuracy: 0.9254 - val_loss: 0.5302 - val_accuracy: 0.8149\n",
      "Epoch 332/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1943 - accuracy: 0.9211 - val_loss: 0.5294 - val_accuracy: 0.8383\n",
      "Epoch 333/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1948 - accuracy: 0.9208 - val_loss: 0.5228 - val_accuracy: 0.8340\n",
      "Epoch 334/500\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.1878 - accuracy: 0.9248 - val_loss: 0.5744 - val_accuracy: 0.8216\n",
      "Epoch 335/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1931 - accuracy: 0.9231 - val_loss: 0.5257 - val_accuracy: 0.8227\n",
      "Epoch 336/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.1889 - accuracy: 0.9251 - val_loss: 0.5183 - val_accuracy: 0.8349\n",
      "Epoch 337/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1835 - accuracy: 0.9280 - val_loss: 0.5382 - val_accuracy: 0.8414\n",
      "Epoch 338/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1861 - accuracy: 0.9266 - val_loss: 0.5347 - val_accuracy: 0.8318\n",
      "Epoch 339/500\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.1929 - accuracy: 0.9228 - val_loss: 0.5363 - val_accuracy: 0.8220\n",
      "Epoch 340/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.1904 - accuracy: 0.9257 - val_loss: 0.5603 - val_accuracy: 0.8307\n",
      "Epoch 341/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1812 - accuracy: 0.9284 - val_loss: 0.5475 - val_accuracy: 0.8278\n",
      "Epoch 342/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.1840 - accuracy: 0.9277 - val_loss: 0.5825 - val_accuracy: 0.8289\n",
      "Epoch 343/500\n",
      "211/211 [==============================] - 37s 174ms/step - loss: 0.1874 - accuracy: 0.9228 - val_loss: 0.5373 - val_accuracy: 0.8311\n",
      "Epoch 344/500\n",
      "211/211 [==============================] - 36s 169ms/step - loss: 0.1872 - accuracy: 0.9256 - val_loss: 0.5298 - val_accuracy: 0.8438\n",
      "Epoch 345/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.1885 - accuracy: 0.9231 - val_loss: 0.5247 - val_accuracy: 0.8274\n",
      "Epoch 346/500\n",
      "211/211 [==============================] - 35s 166ms/step - loss: 0.1862 - accuracy: 0.9254 - val_loss: 0.5186 - val_accuracy: 0.8385\n",
      "Epoch 347/500\n",
      "211/211 [==============================] - 35s 166ms/step - loss: 0.1812 - accuracy: 0.9278 - val_loss: 0.5396 - val_accuracy: 0.8309\n",
      "Epoch 348/500\n",
      "211/211 [==============================] - 37s 175ms/step - loss: 0.1777 - accuracy: 0.9302 - val_loss: 0.5196 - val_accuracy: 0.8305\n",
      "Epoch 349/500\n",
      "211/211 [==============================] - 45s 211ms/step - loss: 0.1851 - accuracy: 0.9280 - val_loss: 0.5416 - val_accuracy: 0.8260\n",
      "Epoch 350/500\n",
      "211/211 [==============================] - 27s 128ms/step - loss: 0.1790 - accuracy: 0.9309 - val_loss: 0.5268 - val_accuracy: 0.8311\n",
      "Epoch 351/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1792 - accuracy: 0.9286 - val_loss: 0.5301 - val_accuracy: 0.8311\n",
      "Epoch 352/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1813 - accuracy: 0.9303 - val_loss: 0.5751 - val_accuracy: 0.8282\n",
      "Epoch 353/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1834 - accuracy: 0.9268 - val_loss: 0.5312 - val_accuracy: 0.8327\n",
      "Epoch 354/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.1776 - accuracy: 0.9296 - val_loss: 0.5532 - val_accuracy: 0.8336\n",
      "Epoch 355/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1773 - accuracy: 0.9318 - val_loss: 0.5735 - val_accuracy: 0.8245\n",
      "Epoch 356/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1790 - accuracy: 0.9306 - val_loss: 0.5717 - val_accuracy: 0.8383\n",
      "Epoch 357/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.5639 - val_accuracy: 0.8202\n",
      "Epoch 358/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1786 - accuracy: 0.9277 - val_loss: 0.5960 - val_accuracy: 0.8131\n",
      "Epoch 359/500\n",
      "211/211 [==============================] - 24s 113ms/step - loss: 0.1786 - accuracy: 0.9289 - val_loss: 0.5760 - val_accuracy: 0.8378\n",
      "Epoch 360/500\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.1729 - accuracy: 0.9305 - val_loss: 0.5582 - val_accuracy: 0.8314\n",
      "Epoch 361/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1629 - accuracy: 0.9375 - val_loss: 0.5835 - val_accuracy: 0.8258\n",
      "Epoch 362/500\n",
      "211/211 [==============================] - 30s 142ms/step - loss: 0.1759 - accuracy: 0.9284 - val_loss: 0.5581 - val_accuracy: 0.8358\n",
      "Epoch 363/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1764 - accuracy: 0.9286 - val_loss: 0.6416 - val_accuracy: 0.8089\n",
      "Epoch 364/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1698 - accuracy: 0.9321 - val_loss: 0.5779 - val_accuracy: 0.8267\n",
      "Epoch 365/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1648 - accuracy: 0.9329 - val_loss: 0.5724 - val_accuracy: 0.8278\n",
      "Epoch 366/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1679 - accuracy: 0.9345 - val_loss: 0.5809 - val_accuracy: 0.8280\n",
      "Epoch 367/500\n",
      "211/211 [==============================] - 24s 114ms/step - loss: 0.1733 - accuracy: 0.9302 - val_loss: 0.6107 - val_accuracy: 0.8162\n",
      "Epoch 368/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1748 - accuracy: 0.9297 - val_loss: 0.5360 - val_accuracy: 0.8360\n",
      "Epoch 369/500\n",
      "211/211 [==============================] - 26s 120ms/step - loss: 0.1702 - accuracy: 0.9345 - val_loss: 0.5893 - val_accuracy: 0.8233\n",
      "Epoch 370/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1680 - accuracy: 0.9341 - val_loss: 0.5913 - val_accuracy: 0.8251\n",
      "Epoch 371/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1795 - accuracy: 0.9271 - val_loss: 0.5703 - val_accuracy: 0.8300\n",
      "Epoch 372/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.1639 - accuracy: 0.9370 - val_loss: 0.6066 - val_accuracy: 0.8298\n",
      "Epoch 373/500\n",
      "211/211 [==============================] - 36s 172ms/step - loss: 0.1657 - accuracy: 0.9355 - val_loss: 0.5942 - val_accuracy: 0.8285\n",
      "Epoch 374/500\n",
      "211/211 [==============================] - 31s 146ms/step - loss: 0.1757 - accuracy: 0.9335 - val_loss: 0.6030 - val_accuracy: 0.8147\n",
      "Epoch 375/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1619 - accuracy: 0.9349 - val_loss: 0.5869 - val_accuracy: 0.8340\n",
      "Epoch 376/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.1648 - accuracy: 0.9330 - val_loss: 0.5999 - val_accuracy: 0.8271\n",
      "Epoch 377/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1645 - accuracy: 0.9339 - val_loss: 0.6097 - val_accuracy: 0.8294\n",
      "Epoch 378/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1687 - accuracy: 0.9335 - val_loss: 0.6193 - val_accuracy: 0.8265\n",
      "Epoch 379/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1588 - accuracy: 0.9378 - val_loss: 0.5937 - val_accuracy: 0.8367\n",
      "Epoch 380/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1679 - accuracy: 0.9358 - val_loss: 0.5865 - val_accuracy: 0.8229\n",
      "Epoch 381/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1627 - accuracy: 0.9358 - val_loss: 0.6031 - val_accuracy: 0.8216\n",
      "Epoch 382/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1604 - accuracy: 0.9375 - val_loss: 0.5831 - val_accuracy: 0.8287\n",
      "Epoch 383/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.1626 - accuracy: 0.9358 - val_loss: 0.6334 - val_accuracy: 0.8227\n",
      "Epoch 384/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1642 - accuracy: 0.9332 - val_loss: 0.6708 - val_accuracy: 0.8147\n",
      "Epoch 385/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1537 - accuracy: 0.9412 - val_loss: 0.6197 - val_accuracy: 0.8309\n",
      "Epoch 386/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1720 - accuracy: 0.9318 - val_loss: 0.5922 - val_accuracy: 0.8316\n",
      "Epoch 387/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.1554 - accuracy: 0.9398 - val_loss: 0.6260 - val_accuracy: 0.8233\n",
      "Epoch 388/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1561 - accuracy: 0.9379 - val_loss: 0.6238 - val_accuracy: 0.8278\n",
      "Epoch 389/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1568 - accuracy: 0.9393 - val_loss: 0.6085 - val_accuracy: 0.8229\n",
      "Epoch 390/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.1644 - accuracy: 0.9326 - val_loss: 0.6253 - val_accuracy: 0.8262\n",
      "Epoch 391/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1581 - accuracy: 0.9370 - val_loss: 0.6171 - val_accuracy: 0.8220\n",
      "Epoch 392/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1562 - accuracy: 0.9366 - val_loss: 0.6250 - val_accuracy: 0.8303\n",
      "Epoch 393/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1512 - accuracy: 0.9358 - val_loss: 0.6532 - val_accuracy: 0.8127\n",
      "Epoch 394/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1562 - accuracy: 0.9373 - val_loss: 0.6664 - val_accuracy: 0.8216\n",
      "Epoch 395/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1631 - accuracy: 0.9338 - val_loss: 0.6204 - val_accuracy: 0.8205\n",
      "Epoch 396/500\n",
      "211/211 [==============================] - 39s 185ms/step - loss: 0.1653 - accuracy: 0.9323 - val_loss: 0.6506 - val_accuracy: 0.8256\n",
      "Epoch 397/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.1508 - accuracy: 0.9396 - val_loss: 0.6212 - val_accuracy: 0.8289\n",
      "Epoch 398/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1556 - accuracy: 0.9382 - val_loss: 0.6606 - val_accuracy: 0.8207\n",
      "Epoch 399/500\n",
      "211/211 [==============================] - 29s 136ms/step - loss: 0.1486 - accuracy: 0.9443 - val_loss: 0.6568 - val_accuracy: 0.8316\n",
      "Epoch 400/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1500 - accuracy: 0.9397 - val_loss: 0.7273 - val_accuracy: 0.8062\n",
      "Epoch 401/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1570 - accuracy: 0.9415 - val_loss: 0.5778 - val_accuracy: 0.8338\n",
      "Epoch 402/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1468 - accuracy: 0.9437 - val_loss: 0.6661 - val_accuracy: 0.8182\n",
      "Epoch 403/500\n",
      "211/211 [==============================] - 25s 116ms/step - loss: 0.1580 - accuracy: 0.9327 - val_loss: 0.6151 - val_accuracy: 0.8314\n",
      "Epoch 404/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.1462 - accuracy: 0.9413 - val_loss: 0.6320 - val_accuracy: 0.8258\n",
      "Epoch 405/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1514 - accuracy: 0.9396 - val_loss: 0.6895 - val_accuracy: 0.8240\n",
      "Epoch 406/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1556 - accuracy: 0.9366 - val_loss: 0.7456 - val_accuracy: 0.7957\n",
      "Epoch 407/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1532 - accuracy: 0.9382 - val_loss: 0.7058 - val_accuracy: 0.8220\n",
      "Epoch 408/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1457 - accuracy: 0.9418 - val_loss: 0.6462 - val_accuracy: 0.8254\n",
      "Epoch 409/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1440 - accuracy: 0.9422 - val_loss: 0.7709 - val_accuracy: 0.8000\n",
      "Epoch 410/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1588 - accuracy: 0.9347 - val_loss: 0.6527 - val_accuracy: 0.8260\n",
      "Epoch 411/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.1465 - accuracy: 0.9404 - val_loss: 0.6802 - val_accuracy: 0.8236\n",
      "Epoch 412/500\n",
      "211/211 [==============================] - 30s 142ms/step - loss: 0.1400 - accuracy: 0.9450 - val_loss: 0.6902 - val_accuracy: 0.8218\n",
      "Epoch 413/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1432 - accuracy: 0.9419 - val_loss: 0.6450 - val_accuracy: 0.8262\n",
      "Epoch 414/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1497 - accuracy: 0.9410 - val_loss: 0.6768 - val_accuracy: 0.8274\n",
      "Epoch 415/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.1488 - accuracy: 0.9403 - val_loss: 0.6689 - val_accuracy: 0.8323\n",
      "Epoch 416/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1339 - accuracy: 0.9489 - val_loss: 0.6622 - val_accuracy: 0.8233\n",
      "Epoch 417/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.1375 - accuracy: 0.9464 - val_loss: 0.6906 - val_accuracy: 0.8303\n",
      "Epoch 418/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.1477 - accuracy: 0.9407 - val_loss: 0.7210 - val_accuracy: 0.8262\n",
      "Epoch 419/500\n",
      "211/211 [==============================] - 42s 202ms/step - loss: 0.1443 - accuracy: 0.9418 - val_loss: 0.6880 - val_accuracy: 0.8316\n",
      "Epoch 420/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1592 - accuracy: 0.9354 - val_loss: 0.6813 - val_accuracy: 0.8280\n",
      "Epoch 421/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1493 - accuracy: 0.9403 - val_loss: 0.7057 - val_accuracy: 0.8294\n",
      "Epoch 422/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.1384 - accuracy: 0.9440 - val_loss: 0.6963 - val_accuracy: 0.8251\n",
      "Epoch 423/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1376 - accuracy: 0.9464 - val_loss: 0.7339 - val_accuracy: 0.8274\n",
      "Epoch 424/500\n",
      "211/211 [==============================] - 30s 143ms/step - loss: 0.1372 - accuracy: 0.9458 - val_loss: 0.7153 - val_accuracy: 0.8155\n",
      "Epoch 425/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.1395 - accuracy: 0.9447 - val_loss: 0.7114 - val_accuracy: 0.8133\n",
      "Epoch 426/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.1412 - accuracy: 0.9428 - val_loss: 0.6711 - val_accuracy: 0.8196\n",
      "Epoch 427/500\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 0.1344 - accuracy: 0.9453 - val_loss: 0.7445 - val_accuracy: 0.8171\n",
      "Epoch 428/500\n",
      "211/211 [==============================] - 37s 177ms/step - loss: 0.1415 - accuracy: 0.9455 - val_loss: 0.6908 - val_accuracy: 0.8256\n",
      "Epoch 429/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.1333 - accuracy: 0.9467 - val_loss: 0.7576 - val_accuracy: 0.8271\n",
      "Epoch 430/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.1383 - accuracy: 0.9424 - val_loss: 0.7063 - val_accuracy: 0.8086\n",
      "Epoch 431/500\n",
      "211/211 [==============================] - 29s 140ms/step - loss: 0.1463 - accuracy: 0.9416 - val_loss: 0.7260 - val_accuracy: 0.8173\n",
      "Epoch 432/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1341 - accuracy: 0.9455 - val_loss: 0.7113 - val_accuracy: 0.8314\n",
      "Epoch 433/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1245 - accuracy: 0.9489 - val_loss: 0.7738 - val_accuracy: 0.8155\n",
      "Epoch 434/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1445 - accuracy: 0.9424 - val_loss: 0.7227 - val_accuracy: 0.8249\n",
      "Epoch 435/500\n",
      "211/211 [==============================] - 30s 143ms/step - loss: 0.1260 - accuracy: 0.9485 - val_loss: 0.7945 - val_accuracy: 0.8171\n",
      "Epoch 436/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.1333 - accuracy: 0.9461 - val_loss: 0.7423 - val_accuracy: 0.8167\n",
      "Epoch 437/500\n",
      "211/211 [==============================] - 26s 124ms/step - loss: 0.1351 - accuracy: 0.9439 - val_loss: 0.7181 - val_accuracy: 0.8311\n",
      "Epoch 438/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.1279 - accuracy: 0.9485 - val_loss: 0.7394 - val_accuracy: 0.8256\n",
      "Epoch 439/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1265 - accuracy: 0.9491 - val_loss: 0.8068 - val_accuracy: 0.8193\n",
      "Epoch 440/500\n",
      "211/211 [==============================] - 40s 191ms/step - loss: 0.1442 - accuracy: 0.9403 - val_loss: 0.8081 - val_accuracy: 0.8149\n",
      "Epoch 441/500\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.1249 - accuracy: 0.9492 - val_loss: 0.7652 - val_accuracy: 0.8151\n",
      "Epoch 442/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1345 - accuracy: 0.9452 - val_loss: 0.7543 - val_accuracy: 0.8318\n",
      "Epoch 443/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1337 - accuracy: 0.9467 - val_loss: 0.8137 - val_accuracy: 0.8133\n",
      "Epoch 444/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.1245 - accuracy: 0.9479 - val_loss: 0.7646 - val_accuracy: 0.8320\n",
      "Epoch 445/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.1250 - accuracy: 0.9519 - val_loss: 0.8197 - val_accuracy: 0.8095\n",
      "Epoch 446/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1262 - accuracy: 0.9510 - val_loss: 0.8684 - val_accuracy: 0.8051\n",
      "Epoch 447/500\n",
      "211/211 [==============================] - 32s 154ms/step - loss: 0.1311 - accuracy: 0.9476 - val_loss: 0.7602 - val_accuracy: 0.8249\n",
      "Epoch 448/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1222 - accuracy: 0.9494 - val_loss: 0.7700 - val_accuracy: 0.8216\n",
      "Epoch 449/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1288 - accuracy: 0.9480 - val_loss: 0.7366 - val_accuracy: 0.8276\n",
      "Epoch 450/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1239 - accuracy: 0.9513 - val_loss: 0.7470 - val_accuracy: 0.8207\n",
      "Epoch 451/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.1194 - accuracy: 0.9499 - val_loss: 0.7930 - val_accuracy: 0.8242\n",
      "Epoch 452/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1150 - accuracy: 0.9538 - val_loss: 0.8069 - val_accuracy: 0.8184\n",
      "Epoch 453/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.1211 - accuracy: 0.9495 - val_loss: 0.7727 - val_accuracy: 0.8242\n",
      "Epoch 454/500\n",
      "211/211 [==============================] - 26s 121ms/step - loss: 0.1238 - accuracy: 0.9485 - val_loss: 0.7774 - val_accuracy: 0.8311\n",
      "Epoch 455/500\n",
      "211/211 [==============================] - 27s 129ms/step - loss: 0.1155 - accuracy: 0.9534 - val_loss: 0.8017 - val_accuracy: 0.8222\n",
      "Epoch 456/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1244 - accuracy: 0.9513 - val_loss: 0.8470 - val_accuracy: 0.8202\n",
      "Epoch 457/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1157 - accuracy: 0.9517 - val_loss: 0.8547 - val_accuracy: 0.8227\n",
      "Epoch 458/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.1209 - accuracy: 0.9498 - val_loss: 0.8132 - val_accuracy: 0.8209\n",
      "Epoch 459/500\n",
      "211/211 [==============================] - 31s 148ms/step - loss: 0.1149 - accuracy: 0.9537 - val_loss: 0.8061 - val_accuracy: 0.8267\n",
      "Epoch 460/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1303 - accuracy: 0.9442 - val_loss: 0.7669 - val_accuracy: 0.8189\n",
      "Epoch 461/500\n",
      "211/211 [==============================] - 26s 123ms/step - loss: 0.1204 - accuracy: 0.9522 - val_loss: 0.7639 - val_accuracy: 0.8202\n",
      "Epoch 462/500\n",
      "211/211 [==============================] - 34s 162ms/step - loss: 0.1172 - accuracy: 0.9534 - val_loss: 0.7953 - val_accuracy: 0.8282\n",
      "Epoch 463/500\n",
      "211/211 [==============================] - 33s 154ms/step - loss: 0.1132 - accuracy: 0.9551 - val_loss: 0.8035 - val_accuracy: 0.8189\n",
      "Epoch 464/500\n",
      "211/211 [==============================] - 28s 131ms/step - loss: 0.1178 - accuracy: 0.9531 - val_loss: 0.8264 - val_accuracy: 0.8247\n",
      "Epoch 465/500\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 0.1411 - accuracy: 0.9427 - val_loss: 0.8414 - val_accuracy: 0.7995\n",
      "Epoch 466/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1133 - accuracy: 0.9532 - val_loss: 0.8393 - val_accuracy: 0.8184\n",
      "Epoch 467/500\n",
      "211/211 [==============================] - 24s 115ms/step - loss: 0.1163 - accuracy: 0.9526 - val_loss: 0.8219 - val_accuracy: 0.8216\n",
      "Epoch 468/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1098 - accuracy: 0.9572 - val_loss: 0.8262 - val_accuracy: 0.8260\n",
      "Epoch 469/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1086 - accuracy: 0.9568 - val_loss: 0.8647 - val_accuracy: 0.8200\n",
      "Epoch 470/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.1067 - accuracy: 0.9566 - val_loss: 0.8345 - val_accuracy: 0.8285\n",
      "Epoch 471/500\n",
      "211/211 [==============================] - 29s 135ms/step - loss: 0.1094 - accuracy: 0.9568 - val_loss: 0.8544 - val_accuracy: 0.8100\n",
      "Epoch 472/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.1132 - accuracy: 0.9548 - val_loss: 0.8295 - val_accuracy: 0.8238\n",
      "Epoch 473/500\n",
      "211/211 [==============================] - 28s 132ms/step - loss: 0.1083 - accuracy: 0.9574 - val_loss: 0.8583 - val_accuracy: 0.8278\n",
      "Epoch 474/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1087 - accuracy: 0.9543 - val_loss: 0.8152 - val_accuracy: 0.8278\n",
      "Epoch 475/500\n",
      "211/211 [==============================] - 39s 183ms/step - loss: 0.1042 - accuracy: 0.9569 - val_loss: 0.8439 - val_accuracy: 0.8249\n",
      "Epoch 476/500\n",
      "211/211 [==============================] - 38s 181ms/step - loss: 0.1138 - accuracy: 0.9541 - val_loss: 0.8877 - val_accuracy: 0.8178\n",
      "Epoch 477/500\n",
      "211/211 [==============================] - 42s 201ms/step - loss: 0.1050 - accuracy: 0.9581 - val_loss: 0.8459 - val_accuracy: 0.8296\n",
      "Epoch 478/500\n",
      "211/211 [==============================] - 38s 178ms/step - loss: 0.1172 - accuracy: 0.9510 - val_loss: 0.8863 - val_accuracy: 0.8066\n",
      "Epoch 479/500\n",
      "211/211 [==============================] - 38s 178ms/step - loss: 0.1174 - accuracy: 0.9529 - val_loss: 0.8763 - val_accuracy: 0.8287\n",
      "Epoch 480/500\n",
      "211/211 [==============================] - 39s 186ms/step - loss: 0.0972 - accuracy: 0.9620 - val_loss: 0.9483 - val_accuracy: 0.8155\n",
      "Epoch 481/500\n",
      "211/211 [==============================] - 42s 200ms/step - loss: 0.1134 - accuracy: 0.9531 - val_loss: 0.9045 - val_accuracy: 0.8147\n",
      "Epoch 482/500\n",
      "211/211 [==============================] - 47s 223ms/step - loss: 0.1033 - accuracy: 0.9589 - val_loss: 0.9404 - val_accuracy: 0.8089\n",
      "Epoch 483/500\n",
      "211/211 [==============================] - 27s 126ms/step - loss: 0.1046 - accuracy: 0.9540 - val_loss: 0.8479 - val_accuracy: 0.8149\n",
      "Epoch 484/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.1031 - accuracy: 0.9596 - val_loss: 0.9008 - val_accuracy: 0.8173\n",
      "Epoch 485/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1116 - accuracy: 0.9544 - val_loss: 0.8553 - val_accuracy: 0.8008\n",
      "Epoch 486/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.1047 - accuracy: 0.9566 - val_loss: 0.9328 - val_accuracy: 0.8100\n",
      "Epoch 487/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.0970 - accuracy: 0.9624 - val_loss: 0.9276 - val_accuracy: 0.8191\n",
      "Epoch 488/500\n",
      "211/211 [==============================] - 28s 133ms/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.9585 - val_accuracy: 0.8182\n",
      "Epoch 489/500\n",
      "211/211 [==============================] - 25s 118ms/step - loss: 0.0990 - accuracy: 0.9615 - val_loss: 0.9398 - val_accuracy: 0.8198\n",
      "Epoch 490/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.1203 - accuracy: 0.9508 - val_loss: 0.9137 - val_accuracy: 0.8213\n",
      "Epoch 491/500\n",
      "211/211 [==============================] - 31s 148ms/step - loss: 0.1029 - accuracy: 0.9580 - val_loss: 1.0200 - val_accuracy: 0.8184\n",
      "Epoch 492/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.1040 - accuracy: 0.9600 - val_loss: 0.9971 - val_accuracy: 0.8118\n",
      "Epoch 493/500\n",
      "211/211 [==============================] - 25s 120ms/step - loss: 0.0983 - accuracy: 0.9595 - val_loss: 0.9486 - val_accuracy: 0.8147\n",
      "Epoch 494/500\n",
      "211/211 [==============================] - 26s 122ms/step - loss: 0.0871 - accuracy: 0.9647 - val_loss: 0.9822 - val_accuracy: 0.8173\n",
      "Epoch 495/500\n",
      "211/211 [==============================] - 32s 150ms/step - loss: 0.0969 - accuracy: 0.9620 - val_loss: 0.9953 - val_accuracy: 0.8216\n",
      "Epoch 496/500\n",
      "211/211 [==============================] - 27s 127ms/step - loss: 0.0972 - accuracy: 0.9605 - val_loss: 1.0410 - val_accuracy: 0.8158\n",
      "Epoch 497/500\n",
      "211/211 [==============================] - 25s 117ms/step - loss: 0.1044 - accuracy: 0.9572 - val_loss: 0.9976 - val_accuracy: 0.8127\n",
      "Epoch 498/500\n",
      "211/211 [==============================] - 26s 125ms/step - loss: 0.0990 - accuracy: 0.9608 - val_loss: 0.9965 - val_accuracy: 0.8200\n",
      "Epoch 499/500\n",
      "211/211 [==============================] - 24s 116ms/step - loss: 0.1009 - accuracy: 0.9590 - val_loss: 0.9826 - val_accuracy: 0.8098\n",
      "Epoch 500/500\n",
      "211/211 [==============================] - 25s 119ms/step - loss: 0.0988 - accuracy: 0.9599 - val_loss: 0.9223 - val_accuracy: 0.8238\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "historyf = model.fit([input_trainR0, input_trainR1], output_trainConj, epochs= 500, batch_size = 32, \n",
    "                     validation_split = 0.4, shuffle= True, callbacks=[callback]) # validation_split = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBest = keras.models.load_model('best_model_10050525.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 7ms/step - loss: 0.3812 - accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3812302052974701, 0.8460304737091064]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate([input_testR0, input_testR1], output_testConj, batch_size= 32)\n",
    "#modelBest.evaluate([input_testR0, input_testR1], output_testConj, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(historyf.history['accuracy'])\n",
    "plt.plot(historyf.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max val_accuracy :0.861884593963623; min val_loss : 0.3428952097892761\n"
     ]
    }
   ],
   "source": [
    "print('max val_accuracy :' + str(max(historyf.history['val_accuracy'])) + '; ' + 'min val_loss : ' + str(min(historyf.history['val_loss'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7476052641868591,\n",
       " 0.7576297521591187,\n",
       " 0.7885943651199341,\n",
       " 0.7794609069824219,\n",
       " 0.7190911173820496,\n",
       " 0.7894853949546814,\n",
       " 0.7972822189331055,\n",
       " 0.7687680721282959,\n",
       " 0.8019603490829468,\n",
       " 0.7714412808418274,\n",
       " 0.8108710050582886,\n",
       " 0.8124303817749023,\n",
       " 0.8182223439216614,\n",
       " 0.8115392923355103,\n",
       " 0.8191133737564087,\n",
       " 0.8200044631958008,\n",
       " 0.8099799752235413,\n",
       " 0.8251280784606934,\n",
       " 0.8157718777656555,\n",
       " 0.7848073244094849,\n",
       " 0.8010692596435547,\n",
       " 0.8298062086105347,\n",
       " 0.8278012871742249,\n",
       " 0.8226776719093323,\n",
       " 0.8351525664329529,\n",
       " 0.8135442137718201,\n",
       " 0.8298062086105347,\n",
       " 0.8269101977348328,\n",
       " 0.8246825337409973,\n",
       " 0.8322566151618958,\n",
       " 0.8295834064483643,\n",
       " 0.8231232166290283,\n",
       " 0.8298062086105347,\n",
       " 0.8302517533302307,\n",
       " 0.8367119431495667,\n",
       " 0.8197816610336304,\n",
       " 0.8175539970397949,\n",
       " 0.8231232166290283,\n",
       " 0.8315883278846741,\n",
       " 0.8102027177810669,\n",
       " 0.824237048625946,\n",
       " 0.8313655853271484,\n",
       " 0.8322566151618958,\n",
       " 0.8304744958877563,\n",
       " 0.8135442137718201,\n",
       " 0.8398306965827942,\n",
       " 0.8088661432266235,\n",
       " 0.8327021598815918,\n",
       " 0.8282468318939209,\n",
       " 0.8324794173240662,\n",
       " 0.8211182951927185,\n",
       " 0.8213410377502441,\n",
       " 0.8329249024391174,\n",
       " 0.8322566151618958,\n",
       " 0.830697238445282,\n",
       " 0.8171085119247437,\n",
       " 0.8122076392173767,\n",
       " 0.8177767992019653,\n",
       " 0.8195589184761047,\n",
       " 0.8286923766136169,\n",
       " 0.8367119431495667,\n",
       " 0.8295834064483643,\n",
       " 0.8269101977348328,\n",
       " 0.8213410377502441,\n",
       " 0.8329249024391174,\n",
       " 0.8322566151618958,\n",
       " 0.8200044631958008,\n",
       " 0.8240142464637756,\n",
       " 0.8244597911834717,\n",
       " 0.8282468318939209,\n",
       " 0.8304744958877563,\n",
       " 0.8269101977348328,\n",
       " 0.818445086479187,\n",
       " 0.8251280784606934,\n",
       " 0.8093116283416748,\n",
       " 0.8251280784606934,\n",
       " 0.8159946799278259,\n",
       " 0.8340387344360352,\n",
       " 0.831142783164978,\n",
       " 0.8322566151618958,\n",
       " 0.836043655872345,\n",
       " 0.8327021598815918,\n",
       " 0.8324794173240662,\n",
       " 0.8275785446166992,\n",
       " 0.8211182951927185,\n",
       " 0.8347070813179016,\n",
       " 0.825796365737915,\n",
       " 0.8197816610336304,\n",
       " 0.8302517533302307,\n",
       " 0.8211182951927185,\n",
       " 0.8148808479309082,\n",
       " 0.8211182951927185,\n",
       " 0.8280240297317505,\n",
       " 0.8173312544822693,\n",
       " 0.8302517533302307,\n",
       " 0.8266874551773071,\n",
       " 0.8302517533302307,\n",
       " 0.8295834064483643,\n",
       " 0.8162174224853516,\n",
       " 0.8269101977348328]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historyf.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 3s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20535856],\n",
       "       [0.9682729 ],\n",
       "       [0.58951306],\n",
       "       ...,\n",
       "       [0.20562437],\n",
       "       [0.87147534],\n",
       "       [0.96062887]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictOnTest = model.predict([input_testR0, input_testR1])\n",
    "predictOnTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiedArrayPredict = myClassify(predictOnTest, 0.5)\n",
    "np.array(classifiedArrayPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OK : agagggtgtactccaagaagaggaagatgaggctagacgtctctgcatggagtatga',\n",
       " 'OK : gcaaaaataaatgcttgactctgtagcgggaaggcgtattatgcacaccccgcgccg',\n",
       " 'OK : ttcgtctccgcgactacgatgagatgcctgagtgcttccgttactggattgtcacca',\n",
       " 'OK : gtactagagaactagtgcattagcttatttttttgttatcatgctaaccacccggcg',\n",
       " 'OK : aaattaaaattttattgacttaggtcactaaatactttaaccaatataggcatagcg',\n",
       " 'OK : tatgaccgaacgagtcaatcagaccgctttgactctggtattactgtgaacattatt',\n",
       " 'OK : taacattaataaataaggaggctctaatggcactcattagccaatcaatcaagaact',\n",
       " 'OK : tttctacaaaacacttgatactgtatgagcatacagtataattgcttcaacagaaca',\n",
       " 'OK : atgcatttttccgcttgtcttcctgagccgactccctataatgcgcctccatcgaca',\n",
       " 'OK : tattggcttgctcaagcatgaactcaaggctgatacggcgagacttgcgagccttgt',\n",
       " 'OK : aacgagtcaatcagaccgctttgactctggtattactgtgaacattattcgtctccg',\n",
       " 'OK : tctgaaatgagctgttgacaattaatcatcgaactagttaactagtacgcaagttca',\n",
       " 'OK : cactaatttattccatgtcacacttttcgcatctttgttatgctatggttatttcat',\n",
       " 'OK : gaggtggctatgtgtatgaccgaacgagtcaatcagaccgctttgactctggtatta',\n",
       " 'OK : catgtcagcctcgacaacttgcataaatgctttcttgtagacgtgccctacgcgctt',\n",
       " 'NOK : tcagaaatattatggtgatgaactgtttttttatccagtataatttgttggcataat',\n",
       " 'OK : ctgcaatttttctattgcggcctgcggagaactccctataatgcgcctccatcgaca',\n",
       " 'OK : tgctgaaaggaggaactatatgcgctcatacgatatgaacgttgagactgccgctga',\n",
       " 'OK : tctcgtggatggacgttcaacattgaggaaggcataacgctactacctgatgtttac',\n",
       " 'OK : cgaacgagtcaatcagaccgctttgactctggtattactgtgaacattattcgtctc',\n",
       " 'OK : cctcaatggcctctaaacgggtcttgaggggttttttgctgaaaggaggaactatat',\n",
       " 'OK : cgacttaatatactgcgacaggacgtccgttctgtgtaaatcgcaatgaaatggttt',\n",
       " 'OK : catcctcgcaccagtcgacgacggtttacgctttacgtatagtggcgacaatttttt',\n",
       " 'OK : aaccattccggttgactcaatgagcatctcgatgcagcgtactcctacatgaataga',\n",
       " 'OK : taaaaaactaacagttgtcagcctgtcccgcttataagatcatacgccgttatacgt',\n",
       " 'OK : aattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaatactaacaaactc',\n",
       " 'OK : ttactgtgaacattattcgtctccgcgactacgatgagatgcctgagtgcttccgtt']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "comparePredictOkNokWithSeq(classifiedArrayPredict, output_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23533559,  0.42990232, -0.25082487, -0.15267515,  0.26705414,\n",
       "         0.41497964,  0.27988416,  0.37338895, -0.29958403, -0.04501176],\n",
       "       [ 0.42684212,  0.07528386,  0.28260273, -0.10901958, -0.15239488,\n",
       "         0.44041243,  0.01431945,  0.2730652 ,  0.4608476 ,  0.46495697],\n",
       "       [ 0.45438316,  0.02100177,  0.29724106, -0.24716143, -0.4676595 ,\n",
       "         0.4724816 , -0.3817394 ,  0.19320472,  0.42271256, -0.05679994],\n",
       "       [ 0.15253878, -0.10971248, -0.04070297, -0.21874414, -0.08176634,\n",
       "         0.28545243, -0.43704703,  0.18602677,  0.22525644,  0.47238237],\n",
       "       [-0.46574974, -0.4418646 , -0.38255867, -0.34078255, -0.23755996,\n",
       "         0.2713209 ,  0.27443305, -0.03233695,  0.24816659, -0.28621373],\n",
       "       [ 0.07085161,  0.39532802, -0.03007789, -0.32714292,  0.49284223,\n",
       "         0.18271512, -0.03359003, -0.21458982, -0.42486927,  0.06511235],\n",
       "       [ 0.2713358 , -0.27115414,  0.34532204, -0.23495436, -0.43641958,\n",
       "        -0.3368862 ,  0.12960823,  0.10995054, -0.19554421, -0.07720792],\n",
       "       [-0.04590143,  0.3942591 ,  0.00566856,  0.19669637, -0.06631317,\n",
       "        -0.42244568, -0.06407813, -0.1728232 ,  0.46452302,  0.21050097],\n",
       "       [ 0.08060884,  0.37193573, -0.354489  , -0.44815534, -0.00615418,\n",
       "        -0.2734092 ,  0.00961146,  0.40794468,  0.34805787,  0.3050058 ],\n",
       "       [-0.13335842, -0.24585015, -0.33572006, -0.45683667, -0.01444119,\n",
       "        -0.10833547, -0.05962682, -0.15336625, -0.36658153,  0.31347117],\n",
       "       [-0.19820169, -0.153704  , -0.04638202,  0.4839829 ,  0.26289713,\n",
       "        -0.2991848 ,  0.3665354 ,  0.22821838,  0.07212699, -0.3094584 ],\n",
       "       [-0.00911083,  0.29570737, -0.16099177, -0.26788437,  0.39560342,\n",
       "        -0.16354184, -0.44186142, -0.35942614,  0.35737228,  0.10719667],\n",
       "       [-0.15877792,  0.34966612,  0.01691701, -0.06887166,  0.12856776,\n",
       "        -0.33047417,  0.20484395,  0.02976446, -0.3235725 , -0.22644459],\n",
       "       [ 0.09975111,  0.4164229 , -0.05972092,  0.4724858 ,  0.07625274,\n",
       "        -0.37556273, -0.41675794,  0.1072961 , -0.22256404,  0.07434572],\n",
       "       [-0.33588484, -0.26314247,  0.48928934, -0.42041746,  0.49042416,\n",
       "        -0.07778177,  0.13300411,  0.34206462,  0.41866353,  0.38699016],\n",
       "       [ 0.25059113,  0.18620391,  0.01138588,  0.03915464, -0.4131867 ,\n",
       "        -0.11133797, -0.00348904,  0.08867157, -0.30682206,  0.0675555 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
